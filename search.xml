<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[django搭建简易博客]]></title>
      <url>%2F2017%2F05%2F22%2Fdjango%E6%90%AD%E5%BB%BA%E7%AE%80%E6%98%93%E5%8D%9A%E5%AE%A2%2F</url>
      <content type="text"><![CDATA[开发环境win10 python3.5 django1.10 前端模板选择了 下载连接：http://www.cssmoban.com/cssthemes/5879.shtml 创建工程python-admin.py startproject my_blog #创建一个名为my_blog项目 cd my_blog python manage.py startapp blog #创建名为blog的app 修改setting.py文件,将app名称blog添加到INSTALLED_APPS中 INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog' ] 这时候我们还需要创建static，templates两个文件夹： static：主要用来存放css，图片等静态文件 在setting.py末尾添加static的路径（将模板里的img，css，js放入这里）： STATICFILES_DIRS = ( os.path.join(BASE_DIR, "static"), ) templates：用来存放html的模板文件（将下载的html模板放入这里） 在TEMPLATES中的’DIRS’后添加templates的路径 os.path.join(BASE_DIR, ‘templates’) TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR, 'templates')] , 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] 首页views.py 123def index(request): return render(request, &apos;index.html&apos;) urls.py from blog.views import index url(r&apos;^$&apos;, index), ^与%之间不添加任何参数 这两行代码的意思为：从blog这个app的views里引入index，访问首页时调用views里的index函数。 运行服务器打开http://127.0.0.1:8000/就会看见首页了。 但这时候点击首页上的地址栏会出错（点击Home，Blog，About，Contact时并不会跳转到正确的页面，而会显示错误）这是因为我们没有添加其他模板的url。仿照首页在views.py和url.py中写出其他模板的操作。 需要注意的是url(r’^$’, index),中^与%之间之所以没有参数是因为这是首页，其他的页面需要添加。 例如：about 页面的url是 url(r&apos;^about/$&apos;, about), 含义：访问about页面时执行about函数 实现上述操作后访问http://127.0.0.1:8000/about，http://127.0.0.1:8000/full-widthhttp://127.0.0.1:8000/contact/这时候应该就能正常访问了 但是我们点击页面的导航栏时会发现页面并不会跳转成功。 实现跳转这时候我们查看模板的代码，发现导航栏的链接为index.html,about.html之类的。现在需要把index.html 改为 /index/about.html 改为 /about/…把所有的都替换了 完成上述步骤后刷新页面后再点击导航栏就能正常跳转了。 到这一步整个博客的前台就完成了，需要开始写后台操作了。 数据库操作采用自带的sqlite数据库 这一步分为两个部分，一个是博客文章的数据库，另一部分是contact页面的数据库。 先看文章部分的数据库， 文章分为标题，标签，时间，正文四个部分 1234567891011class Acticle(models.Model): title = models.CharField(max_length=100) # 博客标题 category = models.CharField(max_length=50,blank=True) # 博客标签 date_time = models.DateTimeField(auto_now_add=True) # 博客日期 content = models.TextField() # 博客正文 def __str__(self): return self.title class Meta: ordering = [&apos;-date_time&apos;] 执行 python manage.py makemigrations python manage.py migrate 然后利用pycharm自带的database查看是否建好表(此功能pycharm的社区版没有) 将数据库和html模板连接起来修改def index(request)： 123456def index(request): message_list = Acticle.objects.all() return render(request, &apos;index.html&apos;, &#123; &apos;message_list&apos;: message_list &#125;) 再修改index.html 12345678910111213141516171819202122232425262728&lt;main class=&quot;col-md-8&quot;&gt; &#123;% for message in message_list %&#125; &lt;article class=&quot;post post-1&quot;&gt; &lt;header class=&quot;entry-header&quot;&gt; &lt;h1 class=&quot;entry-title&quot;&gt; &lt;a href=&quot;&#123;% url &apos;detail&apos; id=message.id %&#125;&quot;&gt;&#123;&#123; message.title &#125;&#125;&lt;/a&gt; &lt;/h1&gt; &lt;div class=&quot;entry-meta&quot;&gt; &lt;span class=&quot;post-category&quot;&gt;&lt;a href=&quot;#&quot;&gt;&#123;&#123; message.category &#125;&#125;&lt;/a&gt;&lt;/span&gt; &lt;span class=&quot;post-date&quot;&gt;&lt;a href=&quot;#&quot;&gt;&#123;&#123; message.date_time &#125;&#125;&lt;/a&gt;&lt;/span&gt; &lt;span class=&quot;post-author&quot;&gt;&lt;a href=&quot;#&quot;&gt;Albert Einstein&lt;/a&gt;&lt;/span&gt; &lt;span class=&quot;comments-link&quot;&gt;&lt;a href=&quot;#&quot;&gt;4 Comments&lt;/a&gt;&lt;/span&gt; &lt;/div&gt; &lt;/header&gt; &lt;div class=&quot;entry-content clearfix&quot;&gt; &#123;&#123; message.content&#125;&#125; &lt;div class=&quot;read-more cl-effect-14&quot;&gt; &lt;a href=&quot;&#123;% url &apos;detail&apos; id=message.id %&#125;&quot; class=&quot;more-link&quot;&gt;Continue reading &lt;span class=&quot;meta-nav&quot;&gt;→&lt;/span&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &#123;% endfor %&#125; &lt;/main&gt; 将html模板中的文章内容替换为 文章标题 文章标签 文章时间 文章正文# 后台操作 #进入http://127.0.0.1:8000/admin/后发现并没有自己写博客的地方，这时候就需要在 app下的admin.py里进行添加admin.py123456from django.contrib import adminfrom blog.models import Acticle# Register your models here.admin.site.register(Acticle) 添加完后刷新界面就会看见 点击Add就会到写文章的页面了，但是我们写正文的地方太简陋了这就需要用到富文本编辑器了 富文本编辑器选择ckeditor(除此之外还有很多优秀的富文本编辑器) 下载官网地址 https://github.com/django-ckeditor/django-ckeditor pip install django-ckeditor 配置将ckeditor添加到INSTALLED_APPS. 在setting.py的最后添加相关的路径 123456STATIC_ROOT = os.path.join(BASE_DIR, &apos;media/cked&apos;)MEDIA_URL = &apos;/media/&apos;MEDIA_ROOT = os.path.join(BASE_DIR, &apos;media&apos;)CKEDITOR_UPLOAD_PATH = os.path.join(MEDIA_ROOT, &apos;media/uploads&apos;)CKEDITOR_JQUERY_URL = &apos;https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js&apos; 然后执行 python manage.py collectstatic 这个命令会将CKEditor里的媒体资源（media resources）复制到STATIC_ROOT所定义的路径里面。 配置好后页面效果为 这时候输入都没有问题，但是HTML内容想显示出来（一直把HTML源码显示出来）产生乱码。 这是因为django的模板系统默认会对输出进行转义，比如把&lt;p&gt;转义成了&lt;p&gt; ，然后再显示出来的时候就如实地显示为&lt;p&gt;。这其实是django设计者的一片好心，不过这里却是画蛇添足了。要解决这个问题只要把默认的转义去掉就好了。 比如原本我们的模板代码是这样的：现在我们把它变成这样：123&#123;% autoescape off %&#125; &#123;&#123;post.content&#125;&#125;&#123;% endautoescape %&#125; 或者直接 效果相同。最后显示正常。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[django留言板]]></title>
      <url>%2F2017%2F05%2F22%2Fdjango%E7%95%99%E8%A8%80%E6%9D%BF%2F</url>
      <content type="text"><![CDATA[本文使用django实现一个留言板功能，代码环境为： windows10 python3.5 django1.10 开发工具： pycharm 很稀奇，这篇博文 hexo g时一直出错，所以就截成了一张长图]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[django学习笔记一]]></title>
      <url>%2F2017%2F05%2F04%2Fdjango%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
      <content type="text"><![CDATA[python简介Django是一个开源的python web框架。采用MVC框架，即模型M(Model),视图V(View),控制器C(Controller)。它最初是被开发来用于管理劳伦斯出版集团旗下的一些以新闻内容为主的网站的，即是CMS（内容管理系统）软件。并于2005年7月在BSD许可证下发布。这套框架是以比利时的吉普赛爵士吉他手Django Reinhardt来命名的。(Django的音乐真不错)。 架构设计Django是一个基于MVC构造的框架。但是在Django中，控制器接受用户输入的部分由框架自行处理，所以 Django 里更关注的是模型（Model）、模板(Template)和视图（Views），称为 MTV模式。它们各自的职责如下： 层次 职责 模型（Model），即数据存取层 处理与数据相关的所有事务： 如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等。 视图（View），即表现层 处理与表现相关的决定： 如何在页面或其他类型文档中进行显示。 模板(Template)，即业务逻辑层 存取模型及调取恰当模板的相关逻辑。模型与模板的桥梁。 从以上表述可以看出Django 视图不处理用户输入，而仅仅决定要展现哪些数据给用户，而Django 模板 仅仅决定如何展现Django视图指定的数据。或者说, Django将MVC中的视图进一步分解为 Django视图 和 Django模板两个部分，分别决定 “展现哪些数据” 和 “如何展现”，使得Django的模板可以根据需要随时替换，而不仅仅限制于内置的模板。 至于MVC控制器部分，由Django框架的URLconf来实现。URLconf机制是使用正则表达式匹配URL，然后调用合适的Python函数。URLconf对于URL的规则没有任何限制，你完全可以设计成任意的URL风格，不管是传统的，RESTful的，或者是另类的。框架把控制层给封装了，无非与数据交互这层都是数据库表的读,写,删除,更新的操作.在写程序的时候，只要调用相应的方法就行了，感觉很方便。程序员把控制层东西交给Django自动完成了。 只需要编写非常少的代码完成很多的事情。所以，它比MVC框架考虑的问题要深一步，因为我们程序员大都在写控制层的程序。现在这个工作交给了框架，仅需写很少的调用代码，大大提高了工作效率。 设计哲学Django的主要目的是简便、快速的开发数据库驱动的网站。它强调代码复用,多个组件可以很方便的以“插件”形式服务于整个框架，Django有许多功能强大的第三方插件，你甚至可以很方便的开发出自己的工具包。这使得Django具有很强的可扩展性。它还强调快速开发和DRY(Do Not Repeat Yourself)原则。 Django基于MVC的设计十分优美： 对象关系映射 (ORM,object-relational mapping)：以Python类形式定义你的数据模型，ORM将模型与关系数据库连接起来，你将得到一个非常容易使用的数据库API，同时你也可以在Django中使用原始的SQL语句。 URL 分派：使用正则表达式匹配URL，你可以设计任意的URL，没有框架的特定限定。像你喜欢的一样灵活。 模版系统：使用Django强大而可扩展的模板语言，可以分隔设计、内容和Python代码。并且具有可继承性。 表单处理：你可以方便的生成各种表单模型，实现表单的有效性检验。可以方便的从你定义的模型实例生成相应的表单。 Cache系统：可以挂在内存缓冲或其它的框架实现超级缓冲 －－ 实现你所需要的粒度。 会话(session)，用户登录与权限检查，快速开发用户会话功能。 国际化：内置国际化系统，方便开发出多种语言的网站。 自动化的管理界面：不需要你花大量的工作来创建人员管理和更新内容。Django自带一个ADMIN site,类似于内容管理系统。 工作机制 用manage.py runserver启动Django服务器时就载入了在同一目录下的settings .py。该文件包含了项目中的配置信息，如前面讲的URLConf等，其中最重要的配置就是ROOT_URLCONF，它告诉Django哪个Python模块应该用作本站的URLConf，默认的是urls .py。 当访问url时Django会根据ROOT_URLCONF的设置来装载URLConf。 然后按顺序逐个匹配URLConf里的URLpatterns。如果找到则会调用相关联的视图函数，并把HttpRequest对象作为第一个参数(通常是request) 最后该view函数负责返回一个HttpResponse对象。 文档官方展示：http://www.djangosites.org/Github： https://github.com/django/django中文文档：http://www.kancloud.cn/wizardforcel/django-chinese-docs-18/98846Djangogirl： Github：https://github.com/DjangoGirls/djangogirls 文档： https://tutorial.djangogirls.org/zh/installation/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django 调试工具：Django Debug Toolbar]]></title>
      <url>%2F2017%2F05%2F03%2FDjango-%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7%EF%BC%9ADjango-Debug-Toolbar%2F</url>
      <content type="text"><![CDATA[django-debug-toolbar是一款django的调试工具。当前的版本是1.7。它适用于Django≥1.8。 文档：http://django-debug-toolbar.readthedocs.org/en/1.3.2/Github：https://github.com/jazzband/django-debug-toolbar 安装pip install django-debug-toolbar 配置在settings.py里的INSTALLED_APPS 增加：’debug_toolbar’: INSTALLD_APP[ 'django.contrib.admin', ''' 'debug_toolbar' ] 在settings.py中添加’debug_toolbar.middleware.DebugToolbarMiddleware’到项目的MIDDLEWARE_CLASSES 内。 MIDDLEWARE_CLASSES[ ''' 'debug_toolbar.middleware.DebugToolbarMiddleware' ] 为防止错误放在最后是最好的选择。 添加 INTERNAL_IPS = (‘127.0.0.1’,) 用于主机域名 INTERNAL_IPS = ('127.0.0.1',), 确保DEBUG选项为true]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[“Django源码分析之权限系统_擒贼先擒王]]></title>
      <url>%2F2017%2F05%2F02%2F%E2%80%9CDjango%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F-%E6%93%92%E8%B4%BC%E5%85%88%E6%93%92%E7%8E%8B%2F</url>
      <content type="text"><![CDATA[Django源码分析之权限系统_擒贼先擒王-博客-云栖社区-阿里云 已剪辑自: https://yq.aliyun.com/articles/43812?spm=5176.100239.blogcont39031.16.hgIRY4摘要： 乍见 Django内置的权限系统已经很完善了，加上django-guardian提供的功能，基本上能满足大部分的权限需求。暂且不说django-guardian，我们先来看下Django内置的权限系统：django.contrib.auth 包。 乍见Django内置的权限系统已经很完善了，加上django-guardian提供的功能，基本上能满足大部分的权限需求。暂且不说django-guardian，我们先来看下Django内置的权限系统：django.contrib.auth 包。 相识一般权限系统分为全局权限和对象权限。Django只提供了一个对象权限的框架，具体实现由第三方库django-gardian完成。我们只看全局权限。 先来看auth包暴露出哪些接口。 django.contrib.auth.__init__.py def load_backend(path): return import_string(path)() def _get_backends(return_tuples=False): backends = [] for backend_path in settings.AUTHENTICATION_BACKENDS: backend = load_backend(backend_path) backends.append((backend, backend_path) if return_tuples else backend) if not backends: raise ImproperlyConfigured( 'No authentication backends have been defined. Does ' 'AUTHENTICATION_BACKENDS contain anything?' ) return backends def get_backends(): return _get_backends(return_tuples=False) 前三个方法都是为了加载backends。一个backend其实就是一个class，必须实现authenticate和get_user两个方法。每当我们这样验证用户时 authenticate(username=’username’, password=’password’)django就会去调用这些backend class，用其提供的方法去验证用户权限。那django是如何知道要调用哪些backend class呢？答案就在settings.py中，默认为 AUTHENTICATION_BACKENDS = ['django.contrib.auth.backends.ModelBackend'] 那Django是如何调用这些backend class的呢？ def authenticate(**credentials): """ If the given credentials are valid, return a User object. """ for backend, backend_path in _get_backends(return_tuples=True): try: inspect.getcallargs(backend.authenticate, **credentials) except TypeError: # This backend doesn't accept these credentials as arguments. Try the next one. continue try: user = backend.authenticate(**credentials) except PermissionDenied: # This backend says to stop in our tracks - this user should not be allowed in at all. return None if user is None: continue # Annotate the user object with the path of the backend. user.backend = backend_path return user # The credentials supplied are invalid to all backends, fire signal user_login_failed.send(sender=__name__, credentials=_clean_credentials(credentials)) 由此可见，Django会在第一个验证正确的backend class调用完成后停止，或者碰到PermissionDenied异常也会停止，所以backend class的顺序也很重要。可以添加自定义的backend class。 def login(request, user): """ Persist a user id and a backend in the request. This way a user doesn't have to reauthenticate on every request. Note that data set during the anonymous session is retained when the user logs in. """ session_auth_hash = '' if user is None: user = request.user if hasattr(user, 'get_session_auth_hash'): session_auth_hash = user.get_session_auth_hash() if SESSION_KEY in request.session: if _get_user_session_key(request) != user.pk or ( session_auth_hash and request.session.get(HASH_SESSION_KEY) != session_auth_hash): # To avoid reusing another user's session, create a new, empty # session if the existing session corresponds to a different # authenticated user. request.session.flush() else: request.session.cycle_key() request.session[SESSION_KEY] = user._meta.pk.value_to_string(user) request.session[BACKEND_SESSION_KEY] = user.backend request.session[HASH_SESSION_KEY] = session_auth_hash if hasattr(request, 'user'): request.user = user rotate_token(request) user_logged_in.send(sender=user.__class__, request=request, user=user) login方法，顾名思义，登录用户，同时设置好session，最后发送登入成功通知 def logout(request): """ Removes the authenticated user's ID from the request and flushes their session data. """ # Dispatch the signal before the user is logged out so the receivers have a # chance to find out *who* logged out. user = getattr(request, 'user', None) if hasattr(user, 'is_authenticated') and not user.is_authenticated(): user = None user_logged_out.send(sender=user.__class__, request=request, user=user) # remember language choice saved to session language = request.session.get(LANGUAGE_SESSION_KEY) request.session.flush() if language is not None: request.session[LANGUAGE_SESSION_KEY] = language if hasattr(request, 'user'): from django.contrib.auth.models import AnonymousUser request.user = AnonymousUser() 相对的，logout方法，负责登出用户，清理session，最后设置当前用户为匿名用户 def get_user_model(): """ Returns the User model that is active in this project. """ try: return django_apps.get_model(settings.AUTH_USER_MODEL) except ValueError: raise ImproperlyConfigured("AUTH_USER_MODEL must be of the form 'app_label.model_name'") except LookupError: raise ImproperlyConfigured( "AUTH_USER_MODEL refers to model '%s' that has not been installed" % settings.AUTH_USER_MODEL ) Django不推荐直接使用User class，而是通知get_user_model方法获取当前的用户class（或者使用settins.AUTH_USER_MODEL）。这是为了防止因为开发者使用了自定义用户class而导致的信息错误。 def update_session_auth_hash(request, user): """ Updating a user's password logs out all sessions for the user if django.contrib.auth.middleware.SessionAuthenticationMiddleware is enabled. This function takes the current request and the updated user object from which the new session hash will be derived and updates the session hash appropriately to prevent a password change from logging out the session from which the password was changed. """ if hasattr(user, 'get_session_auth_hash') and request.user == user: request.session[HASH_SESSION_KEY] = user.get_session_auth_hash() 最后这个方法的使用场景很少。一般我们更新用户密码时，会在session中清除用户登录信息，导致用户需要重新登录。而使用update_session_auth_hash我们就可以在更新用户密码的同时更新用户的session信息，这样，用户就不需要重新登录了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django源码分析之server]]></title>
      <url>%2F2017%2F05%2F01%2FDjango%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Bserver%2F</url>
      <content type="text"><![CDATA[Django源码分析之server-博客-云栖社区-阿里云已剪辑自: https://yq.aliyun.com/articles/39031?spm=5176.100239.blogcont39030.16.KHuvKj摘要： 乍见 Django内置的server基本包括两部分：django.core.servers和django.core.handlers 相识 servers.basehttp是Django自身提供的一个用于开发测试的server模块，其中提供的WSGIServer、ServerHandler、WSGIRequestHandler其实都是属于WSGI server，django只不过是对python内置的WSGI模块simple_server做的一层包装。 乍见Django内置的server基本包括两部分：django.core.servers和django.core.handlers 相识servers.basehttp是Django自身提供的一个用于开发测试的server模块，其中提供的WSGIServer、ServerHandler、WSGIRequestHandler其实都是属于WSGI server，django只不过是对python内置的WSGI模块simple_server做的一层包装。 handlers package包括base.py和wsgi.py两个模块。base.py中只定义了一个BaseHandler类，它复杂一些基础的功能，比如加载中间件，处理异常，获取响应数据等 wsgi.py才是主角，其中最重要的就是WSGIHandler类，它继承了base.py中的BaseHandler，只添加了一个call方法，那为什么添加这个方法呢？ django.core.wsgi import django from django.core.handlers.wsgi import WSGIHandler def get_wsgi_application(): """ The public interface to Django's WSGI support. Should return a WSGI callable. Allows us to avoid making django.core.handlers.WSGIHandler public API, in case the internal WSGI implementation changes or moves in the future. """ django.setup() return WSGIHandler() 可见我们启动server时传入的application其实是WSGIHandler的一个实例，而根据WSGI规范，这个application必须要是callable，python中的callable包括函数、方法以及任何定义了call方法的对象 回到handlers.wsgiclass WSGIHandler(base.BaseHandler): initLock = Lock() request_class = WSGIRequest def call(self, environ, start_response): # Set up middleware if needed. We couldn&#39;t do this earlier, because # settings weren&#39;t available. if self._request_middleware is None: with self.initLock: try: # Check that middleware is still uninitialized. if self._request_middleware is None: self.load_middleware() except: # Unload whatever middleware we got self._request_middleware = None raise set_script_prefix(get_script_name(environ)) signals.request_started.send(sender=self.class, environ=environ) try: request = self.request_class(environ) except UnicodeDecodeError: logger.warning(‘Bad Request (UnicodeDecodeError)’, exc_info=sys.exc_info(), extra={ ‘status_code’: 400, } ) response = http.HttpResponseBadRequest() else: response = self.get_response(request) response._handler_class = self.class status = ‘%s %s’ % (response.status_code, response.reason_phrase) response_headers = [(str(k), str(v)) for k, v in response.items()] for c in response.cookies.values(): response_headers.append((str(‘Set-Cookie’), str(c.output(header=’’)))) start_response(force_str(status), response_headers) if getattr(response, ‘file_to_stream’, None) is not None and environ.get(‘wsgi.file_wrapper’): response = environ[&#39;wsgi.file_wrapper&#39;](response.file_to_stream) return response由于call是一个请求的入口，它需要调用BaseHandler中定义的方法去执行加载中间件等一系列操作和异常处理，除此之外，WSGIHandler还会处理cookie、触发signal等。 至于如何返回响应，具体可看handlers.base模块，大概就是找出请求的path，通过匹配路由，找到并执行用户定义的view方法，执行中间件处理方法，最后返回响应。当然，还有一系列的异常处理。 回想这部分的内容需要对WSGi协议有个大致的了解，可以参考：http://xiaorui.cc/2016/04/16/%E6%89%93%E9%80%A0mvc%E6%A1%86%E6%9E%B6%E4%B9%8Bwsgi%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E5%8F%8A%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django源码分析之执行入口]]></title>
      <url>%2F2017%2F05%2F01%2FDjango%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E6%89%A7%E8%A1%8C%E5%85%A5%E5%8F%A3%2F</url>
      <content type="text"><![CDATA[Django源码分析之执行入口-博客-云栖社区-阿里云已剪辑自: https://yq.aliyun.com/articles/39030#摘要： 魔法门 一般我们启动django，最简单的方法是进入project 目录，这时目录结构是这样的 然后我们执行python manage.py runserver，程序就开始执行了。 那django是如何从一个命令就启动整个server，启动的流程是如何的？ 踏门而入 打开目录下的manage.魔法门 一般我们启动django，最简单的方法是进入project 目录，这时目录结构是这样的 然后我们执行python manage.py runserver，程序就开始执行了。 那django是如何从一个命令就启动整个server，启动的流程是如何的？ 踏门而入 打开目录下的manage.py，内容是这样的： `#!/usr/bin/env python` import os import sys if __name__ == "__main__": os.environ.setdefault("DJANGO_SETTINGS_MODULE", "django_learning.settings") from django.core.management import execute_from_command_line execute_from_command_line(sys.argv) 看来manage.py只是把命令行参数传给django.core.management模块中的execute_from_command_line 函数。 查看execute_from_command_line函数，可以发现实际执行的是ManagementUtility类的excute方法： def execute(self): """ Given the command-line arguments, this figures out which subcommand is being run, creates a parser appropriate to that command, and runs it. """ try: subcommand = self.argv[1] except IndexError: subcommand = 'help' # Display help if no arguments were given. `# Preprocess options to extract --settings and --pythonpath.` `# These options could affect the commands that are available, so they` ` # must be processed early.` parser = CommandParser(None, usage="%(prog)s subcommand [options] [args]", add_help=False) parser.add_argument('--settings') parser.add_argument('--pythonpath') parser.add_argument('args', nargs='*') # catch-all try: options, args = parser.parse_known_args(self.argv[2:]) handle_default_options(options) except CommandError: pass # Ignore any option errors at this point. no_settings_commands = [ 'help', 'version', '--help', '--version', '-h', 'compilemessages', 'makemessages', 'startapp', 'startproject', ] try: settings.INSTALLED_APPS except ImproperlyConfigured as exc: self.settings_exception = exc ` # A handful of built-in management commands work without settings.` ` # Load the default settings -- where INSTALLED_APPS is empty.` if subcommand in no_settings_commands: settings.configure() if settings.configured: `# Start the auto-reloading dev server even if the code is broken.` `# The hardcoded condition is a code smell but we can't rely on a` `# flag on the command class because we haven't located it yet.` if subcommand == 'runserver' and '--noreload' not in self.argv: try: autoreload.check_errors(django.setup)() except Exception: ` # The exception will be raised later in the child process ` `# started by the autoreloader. Pretend it didn't happen by ` ` # loading an empty list of applications.` apps.all_models = defaultdict(OrderedDict) apps.app_configs = OrderedDict() apps.apps_ready = apps.models_ready = apps.ready = True `# In all other cases, django.setup() is required to succeed.` else: django.setup() self.autocomplete() if subcommand == 'help': if '--commands' in args: sys.stdout.write(self.main_help_text(commands_only=True) + '\n') elif len(options.args) < 1: sys.stdout.write(self.main_help_text() + '\n') else: self.fetch_command(options.args[0]).print_help(self.prog_name, options.args[0]) `# Special-cases: We want 'django-admin --version' and` `# 'django-admin --help' to work, for backwards compatibility. ` elif subcommand == 'version' or self.argv[1:] == ['--version']: sys.stdout.write(django.get_version() + '\n') elif self.argv[1:] in (['--help'], ['-h']): sys.stdout.write(self.main_help_text() + '\n') else: self.fetch_command(subcommand).run_from_argv(self.argv) 其中 parser = CommandParser(None, usage="%(prog)s subcommand [options] [args]", add_help=False) parser.add_argument('--settings') parser.add_argument('--pythonpath') parser.add_argument('args', nargs='*') # catch-all try: options, args = parser.parse_known_args(self.argv[2:]) handle_default_options(options) except CommandError: pass # Ignore any option errors at this point. CommandParser其实类似于Argparse的一个解析命令行参数的类，从代码里可以看出我们可以直接在命令行指定settings文件和pythonpath。 no_settings_commands = [ 'help', 'version', '--help', '--version', '-h', 'compilemessages', 'makemessages', 'startapp', 'startproject', ] try: settings.INSTALLED_APPS except ImproperlyConfigured as exc: self.settings_exception = exc `# A handful of built-in management commands work without settings.` `# Load the default settings -- where INSTALLED_APPS is empty.` if subcommand in no_settings_commands: settings.configure() 这块代码就可以解释我们执行python manage.py start project 时django在背后会调用settings.configure方法，这里的settings是指django.conf.LazySettings的一个实例，configure方法其实就是使用 django.conf.global_settings.py中的默认设置创建一份新的配置文件，作为我们新创建的project的settings.py if settings.configured: # Start the auto-reloading dev server even if the code is broken. # The hardcoded condition is a code smell but we can't rely on a # flag on the command class because we haven't located it yet. if subcommand == 'runserver' and '--noreload' not in self.argv: try: autoreload.check_errors(django.setup)() except Exception: # The exception will be raised later in the child process # started by the autoreloader. Pretend it didn't happen by # loading an empty list of applications. apps.all_models = defaultdict(OrderedDict) apps.app_configs = OrderedDict() apps.apps_ready = apps.models_ready = apps.ready = True # In all other cases, django.setup() is required to succeed. else: django.setup() autoreload.check_errors(django.setup)()其实也是调用django.setup方法，而django.setup方法 def setup(): """ Configure the settings (this happens as a side effect of accessing the first setting), configure logging and populate the app registry. """ from django.apps import apps from django.conf import settings from django.utils.log import configure_logging configure_logging(settings.LOGGING_CONFIG, settings.LOGGING) apps.populate(settings.INSTALLED_APPS) 负责初始化日志模块以及所有应用.抽丝剥茧剩下的代码最重要的就是这一句： self.fetch_command(subcommand).run_from_argv(self.argv) fetch_command会根据subcommand（这是我们执行python manage.py rumserver时传入的第二个参数：runserver），去django.core.management.commands中查找对应的command类，然后把所有命令行参数传给run_from_argv方法并执行，在runserver这个示例中，最终会调用django.utils.autoreload中的python_reloader或者jython_reloader新开一个线程： def python_reloader(main_func, args, kwargs): if os.environ.get("RUN_MAIN") == "true": thread.start_new_thread(main_func, args, kwargs) try: reloader_thread() except KeyboardInterrupt: pass else: try: exit_code = restart_with_reloader() if exit_code < 0: os.kill(os.getpid(), -exit_code) else: sys.exit(exit_code) except KeyboardInterrupt: pass 这里的main_func是commands/runserver.py中的inner_run方法： def inner_run(self, *args, **options): # If an exception was silenced in ManagementUtility.execute in order # to be raised in the child process, raise it now. autoreload.raise_last_exception() threading = options.get('use_threading') shutdown_message = options.get('shutdown_message', '') quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C' self.stdout.write("Performing system checks...\n\n") self.check(display_num_errors=True) self.check_migrations() now = datetime.now().strftime('%B %d, %Y - %X') if six.PY2: now = now.decode(get_system_encoding()) self.stdout.write(now) self.stdout.write(( "Django version %(version)s, using settings %(settings)r\n" "Starting development server at http://%(addr)s:%(port)s/\n" "Quit the server with %(quit_command)s.\n" ) % { "version": self.get_version(), "settings": settings.SETTINGS_MODULE, "addr": '[%s]' % self.addr if self._raw_ipv6 else self.addr, "port": self.port, "quit_command": quit_command, }) try: handler = self.get_handler(*args, **options) run(self.addr, int(self.port), handler, ipv6=self.use_ipv6, threading=threading) except socket.error as e: # Use helpful error messages instead of ugly tracebacks. ERRORS = { errno.EACCES: "You don't have permission to access that port.", errno.EADDRINUSE: "That port is already in use.", errno.EADDRNOTAVAIL: "That IP address can't be assigned to.", } try: error_text = ERRORS[e.errno] except KeyError: error_text = force_text(e) self.stderr.write("Error: %s" % error_text) # Need to use an OS exit because sys.exit doesn't work in a thread os._exit(1) except KeyboardInterrupt: if shutdown_message: self.stdout.write(shutdown_message) sys.exit(0) 最关键的是这两条语句： handler = self.get_handler(*args, **options) run(self.addr, int(self.port), handler,ipv6=self.use_ipv6, threading=threading) get_handler会返回django.core.servers.basehttp中定义的一个application（其实就是我们project下的wigs.py中定义的application） 这是run函数的内容 def run(addr, port, wsgi_handler, ipv6=False, threading=False): server_address = (addr, port) if threading: httpd_cls = type(str('WSGIServer'), (socketserver.ThreadingMixIn, WSGIServer), {}) else: httpd_cls = WSGIServer httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6) if threading: `# ThreadingMixIn.daemon_threads indicates how threads will behave on an` `# abrupt shutdown; like quitting the server by the user or restarting` `# by the auto-reloader. True means the server will not wait for thread` `# termination before it quits. This will make auto-reloader faster` `# and will prevent the need to kill the server manually if a thread` `# isn't terminating correctly.` httpd.daemon_threads = True httpd.set_app(wsgi_handler) httpd.serve_forever() 可以看出run函数其实就是启动一个WSGIServer实例（WSGIServer继承python内置类simple_server.WSGIServer），并把handler设置为前面get_handler的返回值]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python基础]]></title>
      <url>%2F2017%2F04%2F23%2Fpython%E5%9F%BA%E7%A1%80%2F</url>
      <content type="text"><![CDATA[python简介python是1989年荷兰人Guido van Rossum（吉多·范罗苏姆）在圣诞节创造的。是一种解释性语言，胶水语言，主要缺点就是慢。现在流行的版本分为python2和python3两大阵营，两大版本有很大的不同，不兼容。 python基础]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[浏览器中输入一个 URL后发生了什么]]></title>
      <url>%2F2017%2F04%2F16%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%AD%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA-URL%E5%90%8E%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
      <content type="text"><![CDATA[本文剪辑自: http://igoro.com/archive/what-really-happens-when-you-navigate-to-a-url/作为一名软件开发人员，您肯定会看到Web应用程序如何工作以及涉及哪些技术的高级画面：浏览器，HTTP，HTML，Web服务器，请求处理程序等。 在本文中，我们将深入了解访问URL时发生的事件顺序。 您在浏览器中输入一个URL 这一切都从这里开始： 2.浏览器查询域名的IP地址 导航的第一步是找出访问域的IP地址。DNS查找进行如下： 浏览器缓存 – 浏览器会缓存DNS记录一段时间。 有趣的是，操作系统没有告诉浏览器储存DNS记录的时间，这样不同浏览器会储存个自固定的一个时间（2分钟到30分钟不等）。 系统缓存 – 如果在浏览器缓存里没有找到需要的记录，浏览器会做一个系统调用（windows里是gethostbyname）。这样便可获得系统缓存中的记录。 路由器缓存 – 接着，前面的查询请求发向路由器，它一般会有自己的DNS缓存。 ISP DNS 缓存 – 接下来要check的就是ISP缓存DNS的服务器。在这一般都能找到相应的缓存记录。 递归搜索 – 你的ISP的DNS服务器从跟域名服务器开始进行递归搜索，从.com顶级域名服务器到Facebook的域名服务器。一般DNS服务器的缓存中会有.com域名服务器中的域名，所以到顶级服务器的匹配过程不是那么必要了。 以下是递归DNS搜索的示意图： 关于DNS的一个令人担忧的是，像wikipedia.org或facebook.com这样的整个域似乎映射到一个IP地址。幸运的是，有办法减轻瓶颈： 循环DNS是DNS查找返回多个IP地址而不是仅一个的解决方案。例如，facebook.com实际上映射到四个IP地址。 负载均衡器是用于监听特定IP地址并将请求转发到其他服务器的硬件。主要站点通常将使用昂贵的高性能负载平衡器。 地理DNS通过将域名映射到不同的IP地址来提高可扩展性，具体取决于客户端的地理位置。这非常适合托管静态内容，以便不同的服务器不必更新共享状态。 Anycast是一种路由技术，其中单个IP地址映射到多个物理服务器。不幸的是，anycast不适合TCP，在这种情况下很少使用。 大多数DNS服务器本身都使用anycast来实现DNS查找的高可用性和低延迟。 3.浏览器向Web服务器发送HTTP请求 您可以非常确定Facebook的主页将不会从浏览器缓存中提供，因为动态页面将非常快速或即时（到期日期设置为过期）到期。 因此，浏览器会将此请求发送到Facebook服务器： GET http://facebook.com/ HTTP/1.1 Accept: application/x-ms-application, image/jpeg, application/xaml+xml, […] User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; […] Accept-Encoding: gzip, deflate Connection: Keep-Alive Host: facebook.com Cookie: datr=1265876274-[…]; locale=en_US; lsd=WW[…]; c_user=2101[…] GET请求命名要提取的URL ： “http://facebook.com/”。浏览器识别自己（User-Agent头），并说明它将接受哪些类型的响应（Accept和Accept-Encoding标头）。该连接头要求服务器以保持TCP连接开放的进一步请求。 该请求还包含浏览器对此域的Cookie。您可能已经知道，Cookie是跟踪不同页面请求之间的网站状态的键值对。因此，Cookie存储登录用户的名称，由服务器分配给用户的密码，用户的某些设置等。Cookie将存储在客户端上的文本文件中，并发送到服务器与每个请求。 有各种工具可让您查看原始的HTTP请求和相应的响应。我最喜欢的查看原始HTTP流量的工具是提示，但还有许多其他工具（例如，FireBug）。这些工具在优化站点时非常有帮助。 除了GET请求之外，您可能熟悉的其他类型的请求是POST请求，通常用于提交表单。GET请求通过URL发送其参数（例如：http：//robozzle.com/puzzle.aspx ？id = 85）。POST请求将其参数发送到请求正文中，位于头部下方。 网址“http://facebook.com/”中的尾部斜杠很重要。在这种情况下，浏览器可以安全地添加斜杠。对于http://example.com/folderOrFile表单的网址，浏览器无法自动添加斜杠，因为folderOrFile是否是文件夹或文件不清楚。在这种情况下，浏览器将不用斜线访问该URL，并且服务器将以重定向进行响应，导致不必要的往返。 4.Facebook服务器以永久重定向方式进行响应 这是Facebook服务器发送回浏览器请求的响应： HTTP/1.1 301 Moved Permanently Cache-Control: private, no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Expires: Sat, 01 Jan 2000 00:00:00 GMT Location: http://www.facebook.com/ P3P: CP=”DSP LAW” Pragma: no-cache Set-Cookie: made_write_conn=deleted; expires=Thu, 12-Feb-2009 05:09:50 GMT; path=/; domain=.facebook.com; httponly Content-Type: text/html; charset=utf-8 X-Cnection: close Date: Fri, 12 Feb 2010 05:09:51 GMT Content-Length: 0 服务器回复了301移动永久响应，告诉浏览器转到“http://www.facebook.com/”而不是“http://facebook.com/”。 有一些有趣的原因为什么服务器坚持重定向，而不是立即响应用户想要查看的网页。 一个原因与搜索引擎排名有关。请参阅如果同一页面有两个URL，例如http://www.igoro.com/和http://igoro.com/，搜索引擎可能会认为它们是两个不同的网站，每个网站的入站链路较少，因此排名较低。搜索引擎了解永久重定向（301），并将来自两个来源的传入链接组合成单个排名。 此外，同一内容的多个网址不是缓存友好的。当一段内容有多个名称时，它可能会在缓存中多次出现。 5.浏览器遵循重定向 浏览器现在知道“http://www.facebook.com/”是正确的URL，因此它会发出另一个GET请求： GET http://www.facebook.com/ HTTP/1.1 Accept: application/x-ms-application, image/jpeg, application/xaml+xml, […] Accept-Language: en-US User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; […] Accept-Encoding: gzip, deflate Connection: Keep-Alive Cookie: lsd=XW[…]; c_user=21[…]; x-referer=[…] Host: www.facebook.com 头信息以之前请求中的意义相同。 6.服务器’处理’请求 服务器将收到GET请求，处理它并发送回应。 这似乎是一个简单的任务，但事实上，这里发生了很多有趣的事情 - 即使在像我的博客这样的简单网站上，更不用说像Facebook这样大规模扩展的网站了。 Web服务器软件Web服务器软件（例如IIS或Apache）收到HTTP请求，并决定执行哪个请求处理程序来处理此请求。请求处理程序是一个程序（在ASP.NET，PHP，Ruby，…中），它读取请求并生成响应的HTML。在最简单的情况下，请求处理程序可以存储在结构反映URL结构的文件层次结构中，例如http://example.com/folder1/page1.aspx URL将映射到文件/ httpdocs / folder1 / page1 .aspx。也可以配置Web服务器软件，以便将URL手动映射到请求处理程序，因此page1.aspx的公共URL可以是http://example.com/folder1/page1。 请求处理程序请求处理程序读取请求，其参数和Cookie。它将读取并可能更新存储在服务器上的一些数据。然后，请求处理程序将生成一个HTML响应。每个动态网站面临的一个有趣的难题是如何存储数据。较小的站点通常会有一个SQL数据库来存储数据，但存储大量数据和/或有许多访问者的站点必须找到一种在多台计算机上分割数据库的方法。解决方案包括分片（基于主键分割多个数据库的表），复制以及使用弱化一致性语义的简化数据库。 保持数据更新便宜的一种技术是将一些工作推迟到批处理作业。例如，Facebook必须及时更新新闻源，但支持“您可能认识的人”功能的数据可能只需要每晚更新（我的猜测，我实际上并不知道如何实现此功能）。批量作业更新导致一些不太重要的数据的统一，但可以使数据更新更快更简单。 7.服务器发回一个HTML响应 以下是服务器生成并发回的响应： HTTP/1.1 200 OK Cache-Control: private, no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Expires: Sat, 01 Jan 2000 00:00:00 GMT P3P: CP=”DSP LAW” Pragma: no-cache Content-Encoding: gzip Content-Type: text/html; charset=utf-8 X-Cnection: close Transfer-Encoding: chunked Date: Fri, 12 Feb 2010 09:05:55 GMT 2b3Tn@[…] 整个响应是36 kB，其中大部分在我修剪结束的字节blob中。 的内容编码头告诉该响应体用gzip算法压缩的浏览器。解压缩Blob后，您会看到您期望的HTML： &lt;!DOCTYPE html PUBLIC “-//W3C//DTD XHTML 1.0 Strict//EN” “http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd&quot;&gt; 除了压缩，标题指定是否以及如何缓存页面，设置的任何Cookie（此响应中无），隐私信息等。 注意将Content-Type设置为text / html的标题。标题指示浏览器将响应内容呈现为HTML，而不是将其作为文件下载。浏览器将使用标题来决定如何解释响应，但也会考虑其他因素，例如URL的扩展。 8.浏览器开始渲染HTML即使在浏览器收到整个HTML文档之前，它也开始渲染网站： 9.浏览器发送嵌入HTML的对象的请求 当浏览器呈现HTML时，它会注意到需要提取其他URL的标签。浏览器将发送GET请求以检索这些文件。 以下是我访问facebook.com的几个URL： 图片http://static.ak.fbcdn.net/rsrc.php/z12E0/hash/8q2anwu7.gifhttp://static.ak.fbcdn.net/rsrc.php/zBS5C/hash/7hwy7at6.gif… CSS样式表http://static.ak.fbcdn.net/rsrc.php/z448Z/hash/2plh8s4n.csshttp://static.ak.fbcdn.net/rsrc.php/zANE1/hash/cvtutcee.css… JavaScript文件http://static.ak.fbcdn.net/rsrc.php/zEMOA/hash/c8yzb6ub.jshttp://static.ak.fbcdn.net/rsrc.php/z6R9L/hash/cq2lgbs8.js… 这些URL中的每一个将通过与HTML页面通过的过程类似的过程。因此，浏览器将在DNS中查找域名，向URL发送请求，重定向等。 但是，静态文件（与动态页面不同）允许浏览器缓存它们。某些文件可能会从缓存中提供，而不必联系服务器。浏览器知道缓存特定文件需要多长时间，因为返回文件的响应包含一个Expires头。此外，每个响应还可以包含一个类似于版本号的ETag标头 - 如果浏览器看到已经具有的文件版本的ETag，则可以立即停止传输。 你能猜出这个URL中的“fbcdn.net”是什么意思？值得一提的是，这意味着“Facebook内容传送网络”。Facebook使用内容传送网络（CDN）分发静态内容 - 图像，样式表和JavaScript文件。因此，这些文件将被复制到全球许多机器。 静态内容通常代表站点的大部分带宽，并且可以轻松地通过CDN进行复制。通常，网站将使用第三方CDN提供商，而不是自己运行CND。例如，Facebook的静态文件由最大的CDN提供商Akamai主办。 作为演示，当您尝试ping static.ak.fbcdn.net时，您将收到akamai.net服务器的响应。此外，有趣的是，如果您ping了URL几次，可能会收到来自不同服务器的响应，这表明后台发生的负载均衡。 10.浏览器发送进一步的异步（AJAX）请求 在Web 2.0的精神下，即使在页面呈现后，客户端也会继续与服务器通信。 例如，Facebook聊天将继续更新您登录的朋友的名单，因为他们来了。要更新您登录的朋友的列表，浏览器中执行的JavaScript必须向服务器发送异步请求。异步请求是一种编程式构造的GET或POST请求，转到特殊URL。在Facebook示例中，客户端向http://www.facebook.com/ajax/chat/buddy_list.php发送POST请求，以获取在线的朋友的列表。 这种模式有时被称为“AJAX”，它代表“异步JavaScript和XML”，尽管没有特别的理由为什么服务器必须将响应格式化为XML。例如，Facebook返回JavaScript代码片段以响应异步请求。 除此之外，提示工具可让您查看浏览器发送的异步请求。事实上，你不仅可以被动地观察请求，还可以修改并重新发送。事实上，这是一个容易“欺骗”AJAX请求的事实，给开发人员带来了记分牌的网络游戏。（显然，请不要以这种方式作弊。） Facebook聊天提供了一个AJAX有趣的问题的例子：将数据从服务器推送到客户端。由于HTTP是请求 - 响应协议，因此聊天服务器无法将新消息推送到客户端。相反，客户端必须每隔几秒轮询服务器，看看是否有任何新消息到达。 长时间轮询是减少这些类型场景中服务器负载的有趣技术。如果服务器在轮询时没有任何新消息，则根本不会发回响应。而且，如果在超时期限内收到了一个此客户端的消息，服务器将发现未完成的请求并返回消息。 结论 希望这可以让您更好地了解不同网页如何协同工作。 更详细的答案 github地址：https://github.com/skyline75489/what-happens-when-zh_CN/blob/master/README.rst]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django Cookie与Session]]></title>
      <url>%2F2017%2F04%2F15%2FDjango-Cookie%E4%B8%8ESession%2F</url>
      <content type="text"><![CDATA[Cookiescookies是浏览器为Web服务器存储的一小段信息,每次浏览器从某个服务器请求页面时，它向服务器回送之前收到的cookies. 存取Cookies创建Cookies def set_cookie(request): # 创建HttpResponse对象 Response = HttpResponse() # 创建cookie Response.set_cookie("CookieKey", "CookieValue") # 删除cookie # Response.delete_cookie("CookieKey") return Response 获取Cookies def set_cookie(request): ''' 创建HttpResponse对象''' Response = HttpResponse() ''' 创建cookie''' Response.set_cookie("CookieKey", "CookieValue") ''' 删除cookie Response.delete_cookie("CookieKey")''' return Response ### 测试Cookies ### Django提供了一个简单的方法来测试用户的浏览器是否接受cookie： ''' urls.py''' from django.conf.urls import url from django.contrib import admin from DjangoProjects import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^test_cookie/', views.test_cookie), url(r'^hello/', views.hello), ] ''' views.py''' from django.http import HttpResponse def test_cookie(request): ''' 植入测试的cookie''' request.session.set_test_cookie() return HttpResponse("a") def hello(request): ''' 获取测试的cookie''' ret = request.session.test_cookie_worked() print(ret) if ret: VAL = "验证成功" '''删除测试的cookie''' request.session.delete_test_cookie() else: VAL = "验证失败" return HttpResponse(VAL) 创建Cookies时的参数 Session你可以用session框架来存取每个访问者任意数据，这些数据在服务器端存储，并对cookie的收发进行了抽象，Cookies只存储数据的哈希会话ID，而不是数据本身，从而避免了大部分的常见cookie问题。 开启Django内的Session功能 编辑settings.py配置文件，修改配置如下： 找到MIDDLEWARE段，确保列表里有‘django.contrib.sessions.middleware.SessionMiddleware’,字段找到INSTALLED_APPS段，确保列表里有‘django.contrib.sessions’,字段编辑settings.py配置文件，找到DATABASES字段进行数据库的配置： DATABASES = { ‘default’: { ‘ENGINE’: ‘django.db.backends.mysql’, ‘NAME’: ‘mydatabase’, ‘USER’: ‘root’, ‘PASSWORD’: ‘as’, ‘HOST’: ‘127.0.0.1’, ‘PORT’: ‘3306’, }}然后再项目的init.py文件加入以下两行配置： import pymysqlpymysql.install_as_MySQLdb()生成数据表 E:\DjangoProjects&gt;python manage.py migrate 在视图内使用SessionSessionMiddleware激活后，每个传给视图(view)函数的第一个参数HttpRequest对象都有一个session属性，这是一个字典型的对象，你可以象用普通字典一样来用它。 from django.http import HttpResponsedef set_session(request): ‘’’ 设置一个session’’’ request.session[“SessionKey”] = “SessionValue” ‘’’ 返回页面一个字符串’’’ return HttpResponse(“session”)def show_session(request): ‘’’ 判断session是否存在’’’ if “SessionKey” in request.session: ‘’’ 获取session的值’’’ ret = request.session[“SessionKey”] ‘’’ 删除session’’’ del request.session[“SessionKey”] else: ret = None return HttpResponse(ret)其他的映射方法，如keys()和items()对request.session同样有效。 session的数据存放在django_session表内 mysql&gt; use mydatabaseDatabase changedmysql&gt; select * from django_session;+———————————-+——————————————————————————————————————————————+—————————-+| session_key | session_data | expire_date |+———————————-+——————————————————————————————————————————————+—————————-+| bvthtagcl257hiv8v2wfqnf03m5268sg | ZjY4ZGM1MzRiZGExOGNhMjI0ODBlMjZjM2JhYjU5ODU2MzU5MjM1Mzp7IjAiOjAsIjEiOjEsIjIiOjIsIjMiOjMsIjQiOjQsIjUiOjUsIjYiOjYsIjciOjcsIjgiOjgsIjkiOjl9 | 2016-08-25 08:33:31.281157 |+———————————-+——————————————————————————————————————————————+—————————-+1 row in set (0.00 sec) 在视图外使用Session进入带django环境变量的Python解释器 E:\DjangoProjects&gt;python manage.py shellPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32Type “help”, “copyright”, “credits” or “license” for more information.(InteractiveConsole) &gt; from django.contrib.sessions.models import Session ‘’’ pk后面的字符是从django_session表内获取的session_key’’’ s = Session.objects.get(pk=’bvthtagcl257hiv8v2wfqnf03m5268sg’)s.expire_datedatetime.datetime(2016, 8, 25, 8, 40, 56, 709091, tzinfo=) ‘’’这是经过加密的数据’’’ s.session_data‘NjdiZGYyODljOTNlMTQ3NmFjZTc0YzRlMmVjNmExYTc1NjZkNzUzNDp7IjAiOjAsIjMiOjMsIjkiOjksIjQiOjQsIjEiOjEsIjciOjcsIjIiOjIsIjYiOjYsIjUiOjUsIjgiOjh9’ 使用get_decoded()来读取实际的session数据s.get_decoded(){‘8’: 8, ‘9’: 9, ‘2’: 2, ‘5’: 5, ‘1’: 1, ‘6’: 6, ‘4’: 4, ‘7’: 7, ‘3’: 3, ‘0’: 0}默认情况下，session只会在发生变化的时候才会存入数据库，比如说，字典赋值或删除，你可以设置SESSION_SAVE_EVERY_REQUEST为True来改变这一缺省行为，如果置为True的话，会话cookie在每次请求的时候都会送出，同时，每次会话cookie送出的时候，其expires参数都会更新。 设置SessionSESSION_EXPIRE_AT_BROWSER_CLOSE 如果cookie没有设置过期时间，当用户关闭浏览器的时候，cookie就自动过期了，你可以改变SESSION_EXPIRE_AT_BROWSER_CLOSE的设置来控制session框架的这一行为。 缺省情况下，SESSION_EXPIRE_AT_BROWSER_CLOSE设置为False，这样，会话cookie可以在用户浏览器中保持有效达SESSION_COOKIE_AGE秒（缺省设置是两周，即1,209,600 秒），如果你不想用户每次打开浏览器都必须重新登陆的话，用这个参数来帮你。 如果SESSION_EXPIRE_AT_BROWSER_CLOSE设置为True，当浏览器关闭时，Django会使cookie失效 SESSION_COOKIE_DOMAIN 使用会话cookie（session cookies）的站点，将它设成一个字符串，就好象“.example.com”以用于跨站点（cross-domain）的cookie，或None以用于单个站点，默认为None SESSION_COOKIE_NAME 会话中使用的cookie的名字。 它可以是任意的字符串。默认为sessionid SESSION_COOKIE_SECURE 是否在session中使用安全cookie，如果设置True , cookie就会标记为安全，这意味着cookie只会通过HTTPS来传输，默认为False]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[“python垃圾回收]]></title>
      <url>%2F2017%2F04%2F15%2F%E2%80%9Cpython%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
      <content type="text"><![CDATA[在解释python垃圾回收前先要解决一个问题： python没有malloc和new，垃圾是怎么产生的？ 内存按管理方式分栈内存和堆内存，堆内存需要向操作系统申请，用完要释放不然会就占着茅坑不干事了。而能够在函数中传递并修改的变量只能用堆内存，python的对象在函数中是引用传递即能修改，所以用的是堆内存，必须malloc，只是python封装了大家看不见而已。例如： class Foo(): def init(self): passf = Foo() #这句就约等于java的 Foo f = new Foo();‘’’python只是把 new啊 malloc啊，隐藏在解释器的实现里了’’’详细了解 作用域和垃圾回收的问题起源 Python的GC模块主要运用了“引用计数”（reference counting）来跟踪和回收垃圾。在引用计数的基础上，还可以通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用的问题。通过“分代回收”（generation collection）以空间换取时间来进一步提高垃圾回收的效率。 引用计数在Python中，大多数对象的生命周期都是通过对象的引用计数来管理的。从广义上来讲，引用计数也是一种垃圾收集机制，而且也是一种最直观，最简单的垃圾收集技术。 原理：当一个对象的引用被创建或者复制时，对象的引用计数加1；当一个对象的引用被销毁时，对象的引用计数减1；当对象的引用计数减少为0时，就意味着对象已经没有被任何人使用了，可以将其所占用的内存释放了。 虽然引用计数必须在每次分配和释放内存的时候加入管理引用计数的动作，然而与其他主流的垃圾收集技术相比，引用计数有一个最大的有点，即“实时性”，任何内存，一旦没有指向它的引用，就会立即被回收。而其他的垃圾收集计数必须在某种特殊条件下（比如内存分配失败）才能进行无效内存的回收。 引用计数机制执行效率问题：引用计数机制所带来的维护引用计数的额外操作与Python运行中所进行的内存分配和释放，引用赋值的次数是成正比的。而这点相比其他主流的垃圾回收机制，比如“标记-清除”，“停止-复制”，是一个弱点，因为这些技术所带来的额外操作基本上只是与待回收的内存数量有关。 如果说执行效率还仅仅是引用计数机制的一个软肋的话，那么很不幸，引用计数机制还存在着一个致命的弱点，正是由于这个弱点，使得侠义的垃圾收集从来没有将引用计数包含在内，能引发出这个致命的弱点就是循环引用（也称交叉引用）。 问题说明： 循环引用可以使一组对象的引用计数不为0，然而这些对象实际上并没有被任何外部对象所引用，它们之间只是相互引用。这意味着不会再有人使用这组对象，应该回收这组对象所占用的内存空间，然后由于相互引用的存在，每一个对象的引用计数都不为0，因此这些对象所占用的内存永远不会被释放。比如： a = []b = []a.append(b)b.append(b)print a[[[…]]]print b[[[…]]]这一点是致命的，这与手动进行内存管理所产生的内存泄露毫无区别。 要解决这个问题，Python引入了其他的垃圾收集机制来弥补引用计数的缺陷：“标记-清除”，“分代回收”两种收集技术。 标记-清除“标记-清除”是为了解决循环引用的问题。可以包含其他对象引用的容器对象（比如：list，set，dict，class，instance）都可能产生循环引用。 我们必须承认一个事实，如果两个对象的引用计数都为1，但是仅仅存在他们之间的循环引用，那么这两个对象都是需要被回收的，也就是说，它们的引用计数虽然表现为非0，但实际上有效的引用计数为0。我们必须先将循环引用摘掉，那么这两个对象的有效计数就现身了。假设两个对象为A、B，我们从A出发，因为它有一个对B的引用，则将B的引用计数减1；然后顺着引用达到B，因为B有一个对A的引用，同样将A的引用减1，这样，就完成了循环引用对象间环摘除。 但是这样就有一个问题，假设对象A有一个对象引用C，而C没有引用A，如果将C计数引用减1，而最后A并没有被回收，显然，我们错误的将C的引用计数减1，这将导致在未来的某个时刻出现一个对C的悬空引用。这就要求我们必须在A没有被删除的情况下复原C的引用计数，如果采用这样的方案，那么维护引用计数的复杂度将成倍增加。 原理：“标记-清除”采用了更好的做法，我们并不改动真实的引用计数，而是将集合中对象的引用计数复制一份副本，改动该对象引用的副本。对于副本做任何的改动，都不会影响到对象生命走起的维护。 这个计数副本的唯一作用是寻找root object集合（该集合中的对象是不能被回收的）。当成功寻找到root object集合之后，首先将现在的内存链表一分为二，一条链表中维护root object集合，成为root链表，而另外一条链表中维护剩下的对象，成为unreachable链表。之所以要剖成两个链表，是基于这样的一种考虑：现在的unreachable可能存在被root链表中的对象，直接或间接引用的对象，这些对象是不能被回收的，一旦在标记的过程中，发现这样的对象，就将其从unreachable链表中移到root链表中；当完成标记后，unreachable链表中剩下的所有对象就是名副其实的垃圾对象了，接下来的垃圾回收只需限制在unreachable链表中即可。 分代回收背景：分代的垃圾收集技术是在上个世纪80年代初发展起来的一种垃圾收集机制，一系列的研究表明：无论使用何种语言开发，无论开发的是何种类型，何种规模的程序，都存在这样一点相同之处。即：一定比例的内存块的生存周期都比较短，通常是几百万条机器指令的时间，而剩下的内存块，起生存周期比较长，甚至会从程序开始一直持续到程序结束。 从前面“标记-清除”这样的垃圾收集机制来看，这种垃圾收集机制所带来的额外操作实际上与系统中总的内存块的数量是相关的，当需要回收的内存块越多时，垃圾检测带来的额外操作就越多，而垃圾回收带来的额外操作就越少；反之，当需回收的内存块越少时，垃圾检测就将比垃圾回收带来更少的额外操作。为了提高垃圾收集的效率，采用“空间换时间的策略”。 原理：将系统中的所有内存块根据其存活时间划分为不同的集合，每一个集合就成为一个“代”，垃圾收集的频率随着“代”的存活时间的增大而减小。也就是说，活得越长的对象，就越不可能是垃圾，就应该减少对它的垃圾收集频率。那么如何来衡量这个存活时间：通常是利用几次垃圾收集动作来衡量，如果一个对象经过的垃圾收集次数越多，可以得出：该对象存活时间就越长。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python 实现各种排序算法]]></title>
      <url>%2F2017%2F04%2F15%2Fpython-%E5%AE%9E%E7%8E%B0%E5%90%84%E7%A7%8D%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[总结了一下常见集中排序的算法,并用python实现 归并排序归并排序也称合并排序，是分治法的典型应用。分治思想是将每个问题分解成个个小问题，将每个小问题解决，然后合并。 具体的归并排序就是，将一组无序数按n/2递归分解成只有一个元素的子项，一个元素就是已经排好序的了。然后将这些有序的子元素进行合并。 合并的过程就是 对 两个已经排好序的子序列，先选取两个子序列中最小的元素进行比较，选取两个元素中最小的那个子序列并将其从子序列中 去掉添加到最终的结果集中，直到两个子序列归并完成。 代码如下： import sys def merge(nums, first, middle, last): '''merge 切片边界,左闭右开并且是了0为开始 ''' lnums = nums[first:middle+1] rnums = nums[middle+1:last+1] lnums.append(sys.maxint) rnums.append(sys.maxint) l = 0 r = 0 for i in range(first, last+1): if lnums[l] < rnums[r]: nums[i] = lnums[l] l+=1 else: nums[i] = rnums[r] r+=1 def merge_sort(nums, first, last): ''''' merge sort merge_sort函数中传递的是下标，不是元素个数 ''' if first < last: middle = (first + last)/2 merge_sort(nums, first, middle) merge_sort(nums, middle+1, last) merge(nums, first, middle,last) if __name__ == '__main__': nums = [10,8,4,-1,2,6,7,3] print 'nums is:', nums merge_sort(nums, 0, 7) print 'merge sort:', nums 稳定，时间复杂度 O(nlog n) 插入排序代码如下： import sysdef insert_sort(a): ‘’’’’ 插入排序 有一个已经有序的数据序列，要求在这个已经排好的数据序列中插入一个数， 但要求插入后此数据序列仍然有序。刚开始 一个元素显然有序，然后插入一 个元素到适当位置，然后再插入第三个元素，依次类推 ‘’’ a_len = len(a) if a_len = 0 and a[j] &gt; key: a[j+1] = a[j] j-=1 a[j+1] = key return aif name == ‘main‘: nums = [10,8,4,-1,2,6,7,3] print ‘nums is:’, nums insert_sort(nums) print ‘insert sort:’, nums稳定，时间复杂度 O(n^2) 交换两个元素的值python中你可以这么写：a, b = b, a，其实这是因为赋值符号的左右两边都是元组 （这里需要强调的是，在python中，元组其实是由逗号“,”来界定的，而不是括号）。 选择排序选择排序(Selection sort)是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到 排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所 有元素均排序完毕。 import sysdef select_sort(a): ‘’’’’ 选择排序 每一趟从待排序的数据元素中选出最小（或最大）的一个元素， 顺序放在已排好序的数列的最后，直到全部待排序的数据元素排完。 选择排序是不稳定的排序方法。 ‘’’ a_len=len(a) for i in range(a_len):#在0-n-1上依次选择相应大小的元素 min_index = i#记录最小元素的下标 for j in range(i+1, a_len):#查找最小值 if(a[j]&lt;a[min_index]): min_index=j if min_index != i:#找到最小元素进行交换 a[i],a[min_index] = a[min_index],a[i] if name == ‘main‘: A = [10, -3, 5, 7, 1, 3, 7] print ‘Before sort:’,A select_sort(A) print ‘After sort:’,A不稳定，时间复杂度 O(n^2) 希尔排序希尔排序，也称递减增量排序算法,希尔排序是非稳定排序算法。该方法又称缩小增量排序，因DL．Shell于1959年提出而得名。 先取一个小于n的整数d1作为第一个增量，把文件的全部记录分成d1个组。所有距离为d1的倍数的记录放在同一个组中。先在各组内进行排序； 然后，取第二个增量d2&lt;d1重复上述的分组和排序，直至所取的增量dt=1(dt&lt;dt-l&lt;…&lt;d2&lt;d1)，即所有记录放在同一组中进行直接插入排序为止。 import sysdef shell_sort(a): ‘’’’’ shell排序 ‘’’ a_len=len(a) gap=a_len/2#增量 while gap&gt;0: for i in range(a_len):#对同一个组进行选择排序 m=i j=i+1 while j&lt;a_len: if a[j]&lt;a[m]: m=j j+=gap#j增加gap if m!=i: a[m],a[i]=a[i],a[m] gap/=2 if name == ‘main‘: A = [10, -3, 5, 7, 1, 3, 7] print ‘Before sort:’,A shell_sort(A) print ‘After sort:’,A不稳定，时间复杂度 平均时间 O(nlogn) 最差时间O(n^s)1&lt;s&lt;2 堆排序 ( Heap Sort )“堆”的定义：在起始索引为 0 的“堆”中： 节点 i 的右子节点在位置 2 * i + 24) 节点 i 的父节点在位置 floor( (i - 1) / 2 ) : 注 floor 表示“取整”操作 堆的特性： 每个节点的键值一定总是大于（或小于）它的父节点 “最大堆”： “堆”的根节点保存的是键值最大的节点。即“堆”中每个节点的键值都总是大于它的子节点。 上移，下移 ： 当某节点的键值大于它的父节点时，这时我们就要进行“上移”操作，即我们把该节点移动到它的父节点的位置， 而让它的父节点到它的位置上，然后我们继续判断该节点，直到该节点不再大于它的父节点为止才停止“上移”。 现在我们再来了解一下“下移”操作。当我们把某节点的键值改小了之后，我们就要对其进行“下移”操作。 方法： 我们首先建立一个最大堆(时间复杂度O(n))，然后每次我们只需要把根节点与最后一个位置的节点交换，然后把最后一个位置排除之外，然后把交换后根节点的堆进行调整(时间复杂度 O(lgn) )，即对根节点进行“下移”操作即可。 堆排序的总的时间复杂度为O(nlgn). 代码如下： ‘’’数组编号从 0开始 ‘’’def left(i): return 2i +1def right(i): return 2i+2 ‘’’保持最大堆性质 使以i为根的子树成为最大堆’’’def max_heapify(A, i, heap_size): if heap_size &lt;= 0: return l = left(i) r = right(i) largest = i # 选出子节点中较大的节点 if l A[largest]: largest = l if r A[largest]: largest = r if i != largest :#说明当前节点不是最大的，下移 A[i], A[largest] = A[largest], A[i] #交换 max_heapify(A, largest, heap_size)#继续追踪下移的点 ‘’’print A ‘’’‘’’ 建堆 ‘’’def bulid_max_heap(A): heap_size = len(A) if heap_size &gt;1: node = heap_size/2 -1 while node &gt;= 0: max_heapify(A, node, heap_size) node -=1 ‘’’堆排序 下标从0开始 ‘’’def heap_sort(A): bulid_max_heap(A) heap_size = len(A) i = heap_size - 1 while i &gt; 0 : A[0],A[i] = A[i], A[0] # 堆中的最大值存入数组适当的位置，并且进行交换 heap_size -=1 # heap 大小 递减 1 i -= 1 # 存放堆中最大值的下标递减 1 max_heapify(A, 0, heap_size)if name == ‘main‘ : A = [10, -3, 5, 7, 1, 3, 7] print ‘Before sort:’,A heap_sort(A) print ‘After sort:’,A不稳定，时间复杂度 O(nlog n) 快速排序快速排序算法和合并排序算法一样，也是基于分治模式。对子数组A[p…r]快速排序的分治过程的三个步骤为： 分解：把数组A[p…r]分为A[p…q-1]与A[q+1…r]两部分，其中A[p…q-1]中的每个元素都小于等于A[q]而A[q+1…r]中的每个元素都大于等于A[q]； 解决：通过递归调用快速排序，对子数组A[p…q-1]和A[q+1…r]进行排序； 合并：因为两个子数组是就地排序的，所以不需要额外的操作。 对于划分partition 每一轮迭代的开始，x=A[r], 对于任何数组下标k，有： 1) 如果p≤k≤i，则A[k]≤x。 2) 如果i+1≤k≤j-1，则A[k]&gt;x。 3) 如果k=r，则A[k]=x。 代码如下： ‘’’快速排序 ‘’’‘’’’划分 使满足 以A[r]为基准对数组进行一个划分，比A[r]小的放在左边， 比A[r]大的放在右边快速排序的分治partition过程有两种方法，一种是上面所述的两个指针索引一前一后逐步向后扫描的方法,另一种方法是两个指针从首位向中间扫描的方法。‘’’‘’’p,r 是数组A的下标 ‘’’def partition1(A, p ,r): ‘’’ 方法一，两个指针索引一前一后逐步向后扫描的方法 ‘’’ x = A[r] i = p-1 j = p while j &lt; r: if A[j] &lt; x: i +=1 A[i], A[j] = A[j], A[i] j += 1 A[i+1], A[r] = A[r], A[i+1] return i+1 def partition2(A, p, r): ‘’’ 两个指针从首尾向中间扫描的方法 ‘’’ i = p j = r x = A[p] while i = x and i &lt; j: j -=1 A[i] = A[j] while A[i]&lt;=x and i &lt; j: i +=1 A[j] = A[i] A[i] = x return i ‘’’quick sort ‘’’ def quick_sort(A, p, r): ‘’’ 快速排序的最差时间复杂度为O(n2)，平时时间复杂度为O(nlgn) ‘’’ if p &lt; r: q = partition2(A, p, r) quick_sort(A, p, q-1) quick_sort(A, q+1, r)if name == ‘main‘: A = [5,-4,6,3,7,11,1,2] print ‘Before sort:’,A quick_sort(A, 0, 7) print ‘After sort:’,A不稳定，时间复杂度 最理想 O(nlogn)最差时间O(n^2) 说下python中的序列： 列表、元组和字符串都是序列，但是序列是什么，它们为什么如此特别呢？序列的两个主要特点是索引操作符和切片操作符。索引操作符让我们可以从序列中抓取一个特定项目。切片操作符让我们能够获取序列的一个切片，即一部分序列,如：a = [‘aa’,’bb’,’cc’], print a[0] 为索引操作，print a[0:2]为切片操作。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[AWS ec2配置ShadowSocks]]></title>
      <url>%2F2017%2F04%2F14%2FAWS-ec2%E9%85%8D%E7%BD%AEShadowSocks%2F</url>
      <content type="text"><![CDATA[因为aws有免费试用一年并且每月15G流量的优惠，所以用aws来搭建自己的梯子最为合算。梯子软件则选择了shadowsocks。 购买aws云主机购买AWA EC2时需要美国的信用卡但我们可以通过淘宝购买，一年大约十几块。 创建并连接实例创建实例： 选择服务器操作系统：这里为ubuntu 随后按照提示一步步的进行下去，注意保存自己的密钥。 此时服务器ip为实例描述中的IPv4 公有 IP。如果win连接到ec2推荐xshell， 填入自己的主机ip，然后点用户身份验证。 配置如图所示，只需要替换为自己的密钥即可，用户名为ubuntu不是root。 安装shadowsocks依赖sudo -s // 获取超级管理员权限 apt-get update // 更新apt-get apt-get install python-pip // 安装python包管理工具pip pip install shadowsocks // 安装shadowsocks ssserver -c /etc/shadowsocks.json -d start // 启动shadowsocks 配置shadowsocksvi /etc/shadowsocks.json (vi打开文件后，按i即可进入编辑状态，编辑完后，按esc退出编辑状态，按:进入命令状态，输入wq即可保存并退出) 单一端口配置： { “server”:”0.0.0.0”,#或者为服务器ip地址 “server_port”:端口, “local_address”:”127.0.0.1”, “local_port”:1080, “password”:”连接密码”, “timeout”:300, “method”:”aes-256-cfb”, “fast_open”:false}多端口配置： { “server”:”0.0.0.0”,#或者为服务器ip地址 “port_password”: { “端口1”: “连接密码1”, “端口2” : “连接密码2” }, “timeout”:300, “method”:”aes-256-cfb”, “fast_open”: false} 开启AWS入站端口在开启如站端口前要先测试服务器ip是否能ping通。如果ping不同就要先要增加如站规则： 所有ICMP-IPV4类型 完成之后EC2就会ping通，然后在添加自己配置的端口。 客户端下载win: https://github.com/shadowsocks/shadowsocks-windows/releases android: https://github.com/shadowsocks/shadowsocks-android]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[常用查找数据结构及算法（Python实现）]]></title>
      <url>%2F2017%2F04%2F11%2F%E5%B8%B8%E7%94%A8%E6%9F%A5%E6%89%BE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E7%AE%97%E6%B3%95%EF%BC%88Python%E5%AE%9E%E7%8E%B0%EF%BC%89%2F</url>
      <content type="text"><![CDATA[常用查找数据结构及算法（Python实现）来源: http://www.cnblogs.com/feixuelove1009/p/6148357.html目录 一、基本概念二、无序表查找三、有序表查找3.1 二分查找(Binary Search)3.2 插值查找3.3 斐波那契查找 四、线性索引查找 4.1 稠密索引4.2 分块索引4.3 倒排索引 五、二叉排序树六、 平衡二叉树七、多路查找树（B树） 7.1 2-3树7.2 2-3-4树7.3 B树7.4 B+树 八、散列表（哈希表） 8.1 散列函数的构造方法8.2 处理散列冲突8.3 散列表查找实现8.4 散列表查找性能分析 参考书目《大话数据结构》 一、基本概念查找（Searching）就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。 查找表（Search Table）：由同一类型的数据元素（或记录）构成的集合关键字（Key）：数据元素中某个数据项的值，又称为键值。主键（Primary Key）：可唯一地标识某个数据元素或记录的关键字。 查找表按照操作方式可分为： 静态查找表（Static Search Table）：只做查找操作的查找表。它的主要操作是：查询某个“特定的”数据元素是否在表中检索某个“特定的”数据元素和各种属性动态查找表（Dynamic Search Table）：在查找中同时进行插入或删除等操作：查找时插入数据查找时删除数据 二、无序表查找也就是数据不排序的线性查找，遍历数据元素。算法分析：最好情况是在第一个位置就找到了，此为O(1)；最坏情况在最后一个位置才找到，此为O(n)；所以平均查找次数为(n+1)/2。最终时间复杂度为O(n) ''' 最基础的遍历无序列表的查找算法 时间复杂度O(n)''' def sequential_search(lis, key): length = len(lis) for i in range(length): if lis[i] == key: return i else: return False if __name__ == '__main__': LIST = [1, 5, 8, 123, 22, 54, 7, 99, 300, 222] result = sequential_search(LIST, 123) print(result) 三、有序表查找查找表中的数据必须按某个主键进行某种排序！ 1. 二分查找(Binary Search)算法核心：在查找表中不断取中间元素与查找值进行比较，以二分之一的倍率进行表范围的缩小。 ‘’’针对有序查找表的二分查找算法 时间复杂度O(log(n))’’’ def binary_search(lis, key): low = 0 high = len(lis) - 1 time = 0 while low &lt; high: time += 1 mid = int((low + high) / 2) if key &lt; lis[mid]: high = mid - 1 elif key &gt; lis[mid]: low = mid + 1 else: print(“times: %s” % time)# 打印折半的次数 return mid print(“times: %s” % time) return Falseif name == ‘main‘: LIST = [1, 5, 7, 8, 22, 54, 99, 123, 200, 222, 444] result = binary_search(LIST, 99) print(result) 2. 插值查找二分查找法虽然已经很不错了，但还有可以优化的地方。有的时候，对半过滤还不够狠，要是每次都排除十分之九的数据岂不是更好？选择这个值就是关键问题，插值的意义就是：以更快的速度进行缩减。 插值的核心就是使用公式：value = (key - list[low])/(list[high] - list[low]) 用这个value来代替二分查找中的1/2。上面的代码可以直接使用，只需要改一句。 ‘’’ 插值查找算法 时间复杂度O(log(n))’’’ def binary_search(lis, key): low = 0 high = len(lis) - 1 time = 0 while low &lt; high: time += 1 ‘’’ 计算mid值是插值算法的核心代码’’’ mid = low + int((high - low) * (key - lis[low])/(lis[high] - lis[low])) print(“mid=%s, low=%s, high=%s” % (mid, low, high)) if key &lt; lis[mid]: high = mid - 1 elif key &gt; lis[mid]: low = mid + 1 else: ‘’’ 打印查找的次数’’’ print(“times: %s” % time) return mid print(“times: %s” % time) return False if name == ‘main‘: LIST = [1, 5, 7, 8, 22, 54, 99, 123, 200, 222, 444] result = binary_search(LIST, 444) print(result)插值算法的总体时间复杂度仍然属于O(log(n))级别的。其优点是，对于表内数据量较大，且关键字分布比较均匀的查找表，使用插值算法的平均性能比二分查找要好得多。反之，对于分布极端不均匀的数据，则不适合使用插值算法。 3. 斐波那契查找由插值算法带来的启发，发明了斐波那契算法。其核心也是如何优化那个缩减速率，使得查找次数尽量降低。使用这种算法，前提是已经有一个包含斐波那契数据的列表F = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144,…] ‘’’斐波那契查找算法时间复杂度O(log(n))’’’ def fibonacci_search(lis, key): ‘’’ 需要一个现成的斐波那契列表。其最大元素的值必须超过查找表中元素个数的数值。’’’ F = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368] low = 0 high = len(lis) - 1 ‘’’为了使得查找表满足斐波那契特性，在表的最后添加几个同样的值 这个值是原查找表的最后那个元素的值 添加的个数由F[k]-1-high决定’’’ k = 0 while high &gt; F[k]-1: k += 1 print(k) i = high while F[k]-1 &gt; i: lis.append(lis[high]) i += 1 print(lis) ‘’’ 算法主逻辑。time用于展示循环的次数。’’’ time = 0 while low &lt;= high: time += 1 ‘’’ 为了防止F列表下标溢出，设置if和else’’’ if k &lt; 2: mid = low else: mid = low + F[k-1]-1 print(“low=%s, mid=%s, high=%s” % (low, mid, high)) if key &lt; lis[mid]: high = mid - 1 k -= 1 elif key &gt; lis[mid]: low = mid + 1 k -= 2 else: if mid &lt;= high: ‘’’ 打印查找的次数’’’ print(“times: %s” % time) return mid else: print(“times: %s” % time) return high print(“times: %s” % time) return Falseif name == ‘main‘: LIST = [1, 5, 7, 8, 22, 54, 99, 123, 200, 222, 444] result = fibonacci_search(LIST, 444) print(result)算法分析：斐波那契查找的整体时间复杂度也为O(log(n))。但就平均性能，要优于二分查找。但是在最坏情况下，比如这里如果key为1，则始终处于左侧半区查找，此时其效率要低于二分查找。 总结：二分查找的mid运算是加法与除法，插值查找则是复杂的四则运算，而斐波那契查找只是最简单的加减运算。在海量数据的查找中，这种细微的差别可能会影响最终的查找效率。因此，三种有序表的查找方法本质上是分割点的选择不同，各有优劣，应根据实际情况进行选择。 #四、线性索引查找# 对于海量的无序数据，为了提高查找速度，一般会为其构造索引表。索引就是把一个关键字与它相对应的记录进行关联的过程。一个索引由若干个索引项构成，每个索引项至少包含关键字和其对应的记录在存储器中的位置等信息。索引按照结构可以分为：线性索引、树形索引和多级索引。线性索引：将索引项的集合通过线性结构来组织，也叫索引表。线性索引可分为：稠密索引、分块索引和倒排索引 稠密索引稠密索引指的是在线性索引中，为数据集合中的每个记录都建立一个索引项。这其实就相当于给无序的集合，建立了一张有序的线性表。其索引项一定是按照关键码进行有序的排列。这也相当于把查找过程中需要的排序工作给提前做了。 分块索引给大量的无序数据集合进行分块处理，使得块内无序，块与块之间有序。这其实是有序查找和无序查找的一种中间状态或者说妥协状态。因为数据量过大，建立完整的稠密索引耗时耗力，占用资源过多；但如果不做任何排序或者索引，那么遍历的查找也无法接受，只能折中，做一定程度的排序或索引。分块索引的效率比遍历查找的O(n)要高一些，但与二分查找的O(logn)还是要差不少。 倒排索引不是由记录来确定属性值，而是由属性值来确定记录的位置，这种被称为倒排索引。其中记录号表存储具有相同次关键字的所有记录的地址或引用（可以是指向记录的指针或该记录的主关键字）。 倒排索引是最基础的搜索引擎索引技术。 五、二叉排序树二叉排序树又称为二叉查找树。它或者是一颗空树，或者是具有下列性质的二叉树： 若它的左子树不为空，则左子树上所有节点的值均小于它的根结构的值；若它的右子树不为空，则右子树上所有节点的值均大于它的根结构的值；它的左、右子树也分别为二叉排序树。 构造一颗二叉排序树的目的，往往不是为了排序，而是为了提高查找和插入删除关键字的速度。 二叉排序树的操作： 查找：对比节点的值和关键字，相等则表明找到了；小了则往节点的左子树去找，大了则往右子树去找，这么递归下去，最后返回布尔值或找到的节点。插入：从根节点开始逐个与关键字进行对比，小了去左边，大了去右边，碰到子树为空的情况就将新的节点链接。删除：如果要删除的节点是叶子，直接删；如果只有左子树或只有右子树，则删除节点后，将子树链接到父节点即可；如果同时有左右子树，则可以将二叉排序树进行中序遍历，取将要被删除的节点的前驱或者后继节点替代这个被删除的节点的位置。 class BSTNode: “”” 定义一个二叉树节点类。 以讨论算法为主，忽略了一些诸如对数据类型进行判断的问题。 “”” def init(self, data, left=None, right=None): “”” 初始化 :param data: 节点储存的数据 :param left: 节点左子树 :param right: 节点右子树 “”” self.data = data self.left = left self.right = right class BinarySortTree: “”” 基于BSTNode类的二叉排序树。维护一个根节点的指针。 “”” def init(self): self._root = None def is_empty(self): return self._root is None def search(self, key): &quot;&quot;&quot; 关键码检索 :param key: 关键码 :return: 查询节点或None &quot;&quot;&quot; bt = self._root while bt: entry = bt.data if key &lt; entry: bt = bt.left elif key &gt; entry: bt = bt.right else: return entry return None def insert(self, key): &quot;&quot;&quot; 插入操作 :param key:关键码 :return: 布尔值 &quot;&quot;&quot; bt = self._root if not bt: self._root = BSTNode(key) return while True: entry = bt.data if key &lt; entry: if bt.left is None: bt.left = BSTNode(key) return bt = bt.left elif key &gt; entry: if bt.right is None: bt.right = BSTNode(key) return bt = bt.right else: bt.data = key return def delete(self, key): &quot;&quot;&quot; 二叉排序树最复杂的方法 :param key: 关键码 :return: 布尔值 &quot;&quot;&quot; p, q = None, self._root # 维持p为q的父节点，用于后面的链接操作 if not q: print(&quot;空树！&quot;) return while q and q.data != key: p = q if key &lt; q.data: q = q.left else: q = q.right if not q: # 当树中没有关键码key时，结束退出。 return # 上面已将找到了要删除的节点，用q引用。而p则是q的父节点或者None（q为根节点时）。 if not q.left: if p is None: self._root = q.right elif q is p.left: p.left = q.right else: p.right = q.right return # 查找节点q的左子树的最右节点，将q的右子树链接为该节点的右子树 # 该方法可能会增大树的深度，效率并不算高。可以设计其它的方法。 r = q.left while r.right: r = r.right r.right = q.right if p is None: self._root = q.left elif p.left is q: p.left = q.left else: p.right = q.left def __iter__(self): &quot;&quot;&quot; 实现二叉树的中序遍历算法, 展示我们创建的二叉排序树. 直接使用python内置的列表作为一个栈。 :return: data &quot;&quot;&quot; stack = [] node = self._root while node or stack: while node: stack.append(node) node = node.left node = stack.pop() yield node.data node = node.right if name == ‘main‘: lis = [62, 58, 88, 48, 73, 99, 35, 51, 93, 29, 37, 49, 56, 36, 50] bs_tree = BinarySortTree() for i in range(len(lis)): bs_tree.insert(lis[i]) # bs_tree.insert(100) bs_tree.delete(58) for i in bs_tree: print(i, end=&quot; &quot;) # print(&quot;\n&quot;, bs_tree.search(4)) 二叉排序树总结： 二叉排序树以链式进行存储，保持了链接结构在插入和删除操作上的优点。在极端情况下，查询次数为1，但最大操作次数不会超过树的深度。也就是说，二叉排序树的查找性能取决于二叉排序树的形状，也就引申出了后面的平衡二叉树。给定一个元素集合，可以构造不同的二叉排序树，当它同时是一个完全二叉树的时候，查找的时间复杂度为O(log(n))，近似于二分查找。当出现最极端的斜树时，其时间复杂度为O(n)，等同于顺序查找，效果最差。 六、 平衡二叉树平衡二叉树（AVL树，发明者的姓名缩写）：一种高度平衡的排序二叉树，其每一个节点的左子树和右子树的高度差最多等于1。 平衡二叉树首先必须是一棵二叉排序树！ 平衡因子（Balance Factor）：将二叉树上节点的左子树深度减去右子树深度的值。 对于平衡二叉树所有包括分支节点和叶节点的平衡因子只可能是-1,0和1，只要有一个节点的因子不在这三个值之内，该二叉树就是不平衡的。 最小不平衡子树：距离插入结点最近的，且平衡因子的绝对值大于1的节点为根的子树。 平衡二叉树的构建思想：每当插入一个新结点时，先检查是否破坏了树的平衡性，若有，找出最小不平衡子树。在保持二叉排序树特性的前提下，调整最小不平衡子树中各结点之间的连接关系，进行相应的旋转，成为新的平衡子树。 下面是由[1,2,3,4,5,6,7,10,9]构建平衡二叉树 七、多路查找树（B树）多路查找树（muitl-way search tree）：其每一个节点的孩子可以多于两个，且每一个结点处可以存储多个元素。对于多路查找树，每个节点可以存储多少个元素，以及它的孩子数的多少是关键，常用的有这4种形式：2-3树、2-3-4树、B树和B+树。 2-3树2-3树：每个结点都具有2个孩子，或者3个孩子，或者没有孩子。 一个2结点包含一个元素和两个孩子（或者没有孩子，不能只有一个孩子）。与二叉排序树类似，其左子树包含的元素都小于该元素，右子树包含的元素都大于该元素。一个3结点包含两个元素和三个孩子（或者没有孩子，不能只有一个或两个孩子）。 2-3树中所有的叶子都必须在同一层次上。 2-3-4树其实就是2-3树的扩展，包括了4结点的使用。一个4结点包含小中大三个元素和四个孩子（或没有孩子）。 B树B树是一种平衡的多路查找树。节点最大的孩子数目称为B树的阶（order）。2-3树是3阶B树，2-3-4是4阶B树。B树的数据结构主要用在内存和外部存储器的数据交互中。 B+树为了解决B树的所有元素遍历等基本问题，在原有的结构基础上，加入新的元素组织方式后，形成了B+树。 B+树是应文件系统所需而出现的一种B树的变形树，严格意义上将，它已经不是最基本的树了。 B+树中，出现在分支节点中的元素会被当做他们在该分支节点位置的中序后继者（叶子节点）中再次列出。另外，每一个叶子节点都会保存一个指向后一叶子节点的指针。所有的叶子节点包含全部的关键字的信息，及相关指针，叶子节点本身依关键字的大小自小到大顺序链接 B+树的结构特别适合带有范围的查找。比如查找年龄在20~30岁之间的人。 八、散列表（哈希表）散列表：所有的元素之间没有任何关系。元素的存储位置，是利用元素的关键字通过某个函数直接计算出来的。这个一一对应的关系函数称为散列函数或Hash函数。采用散列技术将记录存储在一块连续的存储空间中，称为散列表或哈希表（Hash Table）。关键字对应的存储位置，称为散列地址。 散列表是一种面向查找的存储结构。它最适合求解的问题是查找与给定值相等的记录。但是对于某个关键字能对应很多记录的情况就不适用，比如查找所有的“男”性。也不适合范围查找，比如查找年龄20~30之间的人。排序、最大、最小等也不合适。 因此，散列表通常用于关键字不重复的数据结构。比如python的字典数据类型。 设计出一个简单、均匀、存储利用率高的散列函数是散列技术中最关键的问题。但是，一般散列函数都面临着冲突的问题。冲突：两个不同的关键字，通过散列函数计算后结果却相同的现象。collision。 8## .1 散列函数的构造方法 ## 好的散列函数：计算简单、散列地址分布均匀 直接定址法例如取关键字的某个线性函数为散列函数：f(key) = a*key + b (a,b为常数）数字分析法抽取关键字里的数字，根据数字的特点进行地址分配平方取中法将关键字的数字求平方，再截取部分折叠法将关键字的数字分割后分别计算，再合并计算，一种玩弄数字的手段。除留余数法最为常见的方法之一。对于表长为m的数据集合，散列公式为：f(key) = key mod p (p&lt;=m)mod：取模（求余数）该方法最关键的是p的选择，而且数据量较大的时候，冲突是必然的。一般会选择接近m的质数。随机数法选择一个随机数，取关键字的随机函数值为它的散列地址。f(key) = random(key)总结，实际情况下根据不同的数据特性采用不同的散列方法，考虑下面一些主要问题： 计算散列地址所需的时间关键字的长度散列表的大小关键字的分布情况记录查找的频率 8.2 处理散列冲突开放定址法就是一旦发生冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 公式是： 这种简单的冲突解决办法被称为线性探测，无非就是自家的坑被占了，就逐个拜访后面的坑，有空的就进，也不管这个坑是不是后面有人预定了的。线性探测带来的最大问题就是冲突的堆积，你把别人预定的坑占了，别人也就要像你一样去找坑。 改进的办法有二次方探测法和随机数探测法。 再散列函数法发生冲突时就换一个散列函数计算，总会有一个可以把冲突解决掉，它能够使得关键字不产生聚集，但相应地增加了计算的时间。 链接地址法碰到冲突时，不更换地址，而是将所有关键字为同义词的记录存储在一个链表里，在散列表中只存储同义词子表的头指针，如下图：这样的好处是，不怕冲突多；缺点是降低了散列结构的随机存储性能。本质是用单链表结构辅助散列结构的不足。 公共溢出区法其实就是为所有的冲突，额外开辟一块存储空间。如果相对基本表而言，冲突的数据很少的时候，使用这种方法比较合适。8.3 散列表查找实现 下面是一段简单的实现代码： class HashTable: def init(self, size): self.elem = [None for i in range(size)] # 使用list数据结构作为哈希表元素保存方法 self.count = size # 最大表长 def hash(self, key): return key % self.count # 散列函数采用除留余数法 def insert_hash(self, key): “””插入关键字到哈希表内””” address = self.hash(key) # 求散列地址 while self.elem[address]: # 当前位置已经有数据了，发生冲突。 address = (address+1) % self.count # 线性探测下一地址是否可用 self.elem[address] = key # 没有冲突则直接保存。 def search_hash(self, key): “””查找关键字，返回布尔值””” star = address = self.hash(key) while self.elem[address] != key: address = (address + 1) % self.count if not self.elem[address] or address == star: # 说明没找到或者循环到了开始的位置 return False return Trueif name == ‘main‘: list_a = [12, 67, 56, 16, 25, 37, 22, 29, 15, 47, 48, 34] hash_table = HashTable(12) for i in list_a: hash_table.insert_hash(i) for i in hash_table.elem: if i: print((i, hash_table.elem.index(i)), end=” “) print(“\n”) print(hash_table.search_hash(15)) print(hash_table.search_hash(33)) 8.4 散列表查找性能分析如果没发生冲突，则其查找时间复杂度为O(1)，属于最极端的好了。但是，现实中冲突可不可避免的，下面三个方面对查找性能影响较大： 散列函数是否均匀处理冲突的办法散列表的装填因子（表内数据装满的程度）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python3操作文件]]></title>
      <url>%2F2017%2F04%2F10%2Fpython3%E6%93%8D%E4%BD%9C%E6%96%87%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[Python3 文件操作详解 打开文件 -&gt; 操作文件 -&gt; 关闭文件 切记：最后要关闭文件（否则可能会有意想不到的结果） 打开文件文件句柄 = open(‘文件路径’, ‘模式’) 指定文件编码 文件句柄= open(‘文件路径’,’模式’,encoding=’utf-8’) 为了防止忘记关闭文件，可以使用上下文管理器来打开文件 with open(‘文件路径’,’模式’) as 文件句柄: 打开文件的模式有： r，只读模式（默认）。 w，只写模式。【不可读；不存在则创建；存在则删除内容；】 a，追加模式。【可读； 不存在则创建；存在则只追加内容；】 r+，可读写文件。【可读；可写；可追加】 w+，写读 “U”表示在读取时，可以将 \r \n \r\n自动转换成 \n （与 r 或 r+ 模式同使用） rU r+U “b”表示处理二进制文件（如：FTP发送上传ISO镜像文件，linux可忽略，windows处理二进制文件时需标注） rb wb ab 关闭文件文件句柄.close() 操作文件： detach .#占位 fileno（返回文件描述符,用于底层操作系统的 I/O 操作） fid = 文件句柄.fileno() print(fid) flush（刷新缓冲区，将缓冲区中的数据立刻写入文件） 文件句柄.flush() isatty（判断文件是否连接到一个终端设备，返回布尔值） 文件句柄.isatty() read（从文件中读取指定的字符数，默认读取全部） str = 文件句柄.read() #读取整个文件 str1 = 文件句柄.read(10) #读取文件前10个字符 readable（判断文件是否可读，返回布尔值） 文件句柄.readable() readline（每次最多读取一行数据，每行的最后包含换行符’\n’） print(文件句柄.readline()) #读取第一行数据 print(文件句柄.readline(3)) #读取第二行前3个字符 print(文件句柄.readline()) #读取第二行剩余字符 print(文件句柄.readline()) #读取第三行 seek（移动文件读取的指针，如果文件中包含中文，移动指针必须是3的倍数，不然会报错，因为一个中文字符等于3个字节） 文件句柄.seek(6) seekable（判断文件指针是否可用，返回布尔值） 文件句柄.seekable() tell（获取指针位置） 文件句柄.tell() truncate（截断，把指针后面的内容删除，并写入文件，要在可写模式下操作） f = open(‘text.txt’,’r+’,encoding=’utf-8’) f.seek(9) #把指针移动到第9个字节后面（即第3个中文后面） f.truncate() #把第3个中文后面的字符删除，并写入文件 f.close() writable（判断文件是否可写，返回布尔值） 文件句柄.writable() write（把字符串写入文件，并返回字符数） 文件句柄.write(‘字符串’)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python 装饰器]]></title>
      <url>%2F2017%2F03%2F03%2FPython-%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
      <content type="text"><![CDATA[装饰模式有很多经典的使用场景，例如插入日志、性能测试、事务处理等等，有了装饰器，就可以提取大量函数中与本身功能无关的类似代码，从而达到代码重用的目的。下面就一步步看看Python中的装饰器。 装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 一个简单例子def niu(): print(&apos;i am niu&apos;) 现在有一个新的需求，希望可以记录下函数的执行日志，于是在代码中添加日志代码： def niu(): print(&apos;i am niu&apos;) logging.info(&quot;niu is running&quot;) bar()、bar2()也有类似的需求，怎么做？再写一个logging在bar函数里？这样就造成大量雷同的代码，为了减少重复写代码，我们可以这样做，重新定义一个函数：专门处理日志 ，日志处理完之后再执行真正的业务代码 def use_logging(func): logging.warn("%s is running" % func.__name__) func() def bar(): print('i am bar') use_logging(bar) 逻辑上不难理解， 但是这样的话，我们每次都要将一个函数作为参数传递给use_logging函数。而且这种方式已经破坏了原有的代码逻辑结构，之前执行业务逻辑时，执行运行bar()，但是现在不得不改成use_logging(bar)。那么有没有更好的方式的呢？当然有，答案就是装饰器。 简单装饰器 def use_logging(func): def wrapper(*args, **kwargs): logging.warn("%s is running" % func.__name__) return func(*args, **kwargs) return wrapper def niu(): print('i am niu') niu = use_logging(niu) niu() 函数use_logging就是装饰器，它把执行真正业务方法的func包裹在函数里面，看起来像bar被use_logging装饰了。在这个例子中，函数进入和退出时 ，被称为一个横切面(Aspect)，这种编程方式被称为面向切面的编程(Aspect-Oriented Programming)。 @符号是装饰器的语法糖，在定义函数的时候使用，避免再一次赋值操作 def use_logging(func): def wrapper(*args, **kwargs): logging.warn("%s is running" % func.__name__) return func(*args) return wrapper @use_logging def foo(): print("i am too") @use_logging def niu(): print("i am niu") niu() 如上所示，这样我们就可以省去bar = use_logging(bar)这一句了，直接调用bar()即可得到想要的结果。如果我们有其他的类似函数，我们可以继续调用装饰器来修饰函数，而不用重复修改函数或者增加新的封装。这样，我们就提高了程序的可重复利用性，并增加了程序的可读性。 装饰器在Python使用如此方便都要归因于Python的函数能像普通的对象一样能作为参数传递给其他函数，可以被赋值给其他变量，可以作为返回值，可以被定义在另外一个函数内。 # 带参数的装饰器 # 装饰器还有更大的灵活性，例如带参数的装饰器：在上面的装饰器调用中，比如@use_logging，该装饰器唯一的参数就是执行业务的函数。装饰器的语法允许我们在调用时，提供其它参数，比如@decorator(a)。这样，就为装饰器的编写和使用提供了更大的灵活性。 def use_logging(level): def decorator(func): def wrapper(*args, **kwargs): if level == "warn": logging.warn("%s is running" % func.__name__) return func(*args) return wrapper return decorator @use_logging(level="warn") def foo(name='foo'): print("i am %s" % name) foo() 上面的use_logging是允许带参数的装饰器。它实际上是对原有装饰器的一个函数封装，并返回一个装饰器。我们可以将它理解为一个含有参数的闭包。当我 们使用@use_logging(level=”warn”)调用的时候，Python能够发现这一层的封装，并把参数传递到装饰器的环境中。 类装饰器再来看看类装饰器，相比函数装饰器，类装饰器具有灵活度大、高内聚、封装性等优点。使用类装饰器还可以依靠类内部的__call__方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。 class Foo(object): def __init__(self, func): self._func = func def __call__(self): print ('class decorator runing') self._func() print ('class decorator ending') @Foo def bar(): print ('bar') bar() functools.wraps使用装饰器极大地复用了代码，但是他有一个缺点就是原函数的元信息不见了，比如函数的docstring、name、参数列表，先看例子： 装饰器 def logged(func): def with_logging(*args, **kwargs): print func.__name__ + " was called" return func(*args, **kwargs) return with_logging 函数 @logged def f(x): """does some math""" return x + x * x 该函数完成等价于： def f(x): """does some math""" return x + x * x f = logged(f) 不难发现，函数f被with_logging取代了，当然它的docstring，__name__就是变成了with_logging函数的信息了。 print f.__name__ # prints 'with_logging' print f.__doc__ # prints None 这个问题就比较严重的，好在我们有functools.wraps，wraps本身也是一个装饰器，它能把原函数的元信息拷贝到装饰器函数中，这使得装饰器函数也有和原函数一样的元信息了。 from functools import wraps def logged(func): @wraps(func) def with_logging(*args, **kwargs): print func.__name__ + " was called" return func(*args, **kwargs) return with_logging @logged def f(x): """does some math""" return x + x * x print f.__name__ # prints 'f' print f.__doc__ # prints 'does some math' 内置装饰器@staticmathod、@classmethod、@property 装饰器的顺序@a@b@cdef f ():等效于 f = a(b(c(f)))]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[互联网之子]]></title>
      <url>%2F2017%2F02%2F15%2F%E4%BA%92%E8%81%94%E7%BD%91%E4%B9%8B%E5%AD%90%2F</url>
      <content type="text"><![CDATA[《互联网之子》讲的是编程天才和信息活动家 亚伦·斯沃茨 的故事。 从参与基础互联网协议RSS到联合创办Reddit，斯沃茨的足迹遍及整个互联网。 但斯沃茨在社会公正和政治组织方面的开创性工作，以及对信息存取的雄心壮志， 使他陷入了一场两年之久的法律噩梦。 这场战斗最终以他结束自己26岁的生命而收场。 如果要问什么是互联网精神的核心？我会回答「开放与自由」。从这个意义上来说，互联网早已超出技术的范畴，成为社会变革的一部分。这个世界上就有这么一群不为商业利益的黑客（Hacker），为了让信息更快地流动，让人们更容易地获取知识，一直在不懈地打破旧世界的藩篱。亚伦·斯沃茨（Aaron Swartz）正是其中一个耀眼的天才。 亚伦从小就对互联网着迷，13岁时参与了 RSS 1.0 标准的制定，15岁时参与了CC知识共享协议（Creative Commons）的创建，而后和 John Gruber 共同发明了Markdown，同时还是著名社交新闻网站 Reddit 的联合创始人。他和其他黑客一样厌恶学校的教育和大公司的工作，从斯坦福大学退学后，他去了刚刚成立的创业孵化器 Y Combinator，并成为第一批毕业生。而当 Reddit 被收购，公司不再是四人小团队时，他也选择了离开。他的理想并不是创办一个能取得商业成功的公司，而是推动知识和信息的自由流动，确保民众享有获取公共知识的权利。从这个角度来说，他并不单纯是一个技术极客或者创业者，而是政治运动的组织者。 RSS 可以让人们很方便地订阅互联网上的内容源，利用类似 Google Reader 这样的订阅器，人们可以将平时所关注的博客和新闻整理到一起，时刻获取最新的内容。而CC协议则是针对传统的 Copyright（保留所有著作权），遵循CC协议的作品只是保留部分权利，其他人可以免费自由地传播这些作品（前提是不能作为商业用途）。CC协议的创始人（也是亚伦的导师）莱斯格(Lawrence Lessig)写的书《代码2.0》就采用了CC原则，它的翻译权也不再被国内出版社所垄断。亚伦还参与创建了 Open Library 项目，他搜集了美国国国会图书馆里的公共数据，尝试为所有书籍建立网络档案，共享给所有人。 亚伦痛恨一切不合理的为了赚钱而阻碍知识传播的行为，当他得知人们在 PACER (联邦法庭记录的电子仓库)上浏览联邦法律文件竟然需要每页都缴费后，便用程序将图书馆里可以获取的法律文档下载下来，上传到 Public.Resource.Org 上供所有人免费查看。尽管这并不违法，但却引起了 FBI 的注意，也让年轻的他第一次面临来自公权力的压力。而后把他逼上绝路的同样是一次下载。众所周知，很多学术期刊的版权掌握在出版社手中，大部分人是无法免费浏览这些论文的。为了尝试共享这些资料，身为哈佛大学研究员的亚伦利用身份的优势，潜入 MIT 的机房，通过 MIT 的网络下载了大量 JSTOR 上的学术期刊文章。这回他遭到了美国特勤局和警方的钓鱼执法，于2011年1月被抓获。 之后是漫长的指控过程，为了杀鸡儆猴，检方最终对亚伦提出了13项重罪的指控，他可能面临几十年的牢狱之灾和100万美元的罚金。这一切最终让深陷抑郁症的亚伦在2013年1月11日自杀，年仅26岁。 信息就是力量。但就像所有力量一样，有些人只想占为己有。世界上所有的科学和文化遗产，已在书籍和期刊上发布了数个世纪，正渐渐地被少数私有的公司数字化并上锁。想要阅读那些有着最著名研究成果的论文？你必须支付给如 Reed Elsevier 这样的出版商大把钱。强迫学者付费才能看到同事们的工作？扫描了所有图书馆，却只允许人们通过谷歌阅读？只为第一世界名牌大学的学生提供科学文献，却不给第三世界国家的孩子们？这是无耻和不可接受的。 亚伦·斯沃茨《游击队开放访问宣言》 （Guerilla Open Access Manifesto）他在自杀前曾经领导过一场漂亮的胜利，那就是反对 SOPA （禁止网络盗版法案）的运动。这是亚伦短暂一生中的高光时刻，也是互联网力量在推动社会革新上的一次闪耀。SOPA 的初衷是保护版权，但实际的处理方式严重动摇了互联网信息开放的根基，并要求互联网平台进行自我审查，这是绝大部分互联网公司所不能容忍的。而支持 SOPA 的则是传统的版权方，包括出版公司，唱片公司，电影公司等，这背后蕴藏着巨大的利益。SOPA 提出时得到了很多国会议员的支持，信奉信息自由的亚伦自然不希望这个法案通过，为此他创办了「求进会」（Demand Progress），通过组织群众游说号召普通民众一起给国会请愿反对 SOPA。 在 SOPA 上，国会议员们显然低估了网民的力量。从全球著名域名商 GoDaddy 的倒戈便能看出来：GoDaddy 最初支持 SOPA，而这一举动引起了众多站长的抗议，包括维基百科在内的许多网站在两天之内迅速从 GoDaddy 撤出了37000多个域名，GoDaddy 于是迅速表示转投反对阵营。2012年1月18日，维基百科，Reddit，Craigslist， Mozilla 等网站决定关站24小时以表示抗议，这一天国会的电话被打爆，形势迅速发生逆转，第二天许多原来支持 SOPA 的议员被撼动，站到了反对的一边，最终 SOPA 没有被国会通过。亚伦非常高兴，这是他一生当中为数不多的胜利时刻，这一刻让他觉得自己的理念在现实世界中是行得通的。 毫无疑问，互联网已经渗入到我们生活的方方面面。即便是 SOPA 这样有巨大利益集团和政治力量所推进的法案也敌不过千千万万使用互联网的普通民众。如果一个网络公司支持 SOPA，用户可以用脚投票让它无法存活；如果有人动摇互联网的根基，各大互联网公司会毫不犹豫地进行联合抗议，它们造成的放大效应比街头抗议强上数百倍。SOPA 的推行者们没有意识到这样一个逆流而动的法案所面对的阻力是如此之大，而亚伦也没有意识到互联网的力量在政治上已经相当成熟，他刚开始并没有抱太大希望。无论如何，这是美国政治史上的大事件，亚伦也成为了这个大事件中的大人物。 亚伦在街头演说 然而这场胜利并没有改变亚伦的结局。检方靠着已经过时的《计算机欺诈与滥用法案》增加了对亚伦的重罪控诉，而亚伦也拒绝了可以带来宽限的认罪。亚伦被捕后，JSTOR 放弃了对他的起诉，政府一直想要杀一儆百，曾被认为是黑客精神发源地的 MIT 则保持中立，坐视不管。自由无拘束的生活被这件案子搅乱，生性敏感脆弱的亚伦也陷入过抑郁症的困扰，背负了巨大精神压力和经济负担的他最终选择在案件开庭审理前自杀，未留下任何遗言。很多人为此感到沮丧与愤怒，汹涌的情绪中夹杂着对天才少年的惋惜，对政府赶尽杀绝的不满，对 MIT 背叛黑客精神的失望，还有对这个病态社会的控诉。 万维网的发明者，同时也是亚伦的好朋友蒂姆·伯纳斯·李爵士哀伤地写道： Wanderers in this crazy world,we have lost a mentor, a wise elder. Hackers for right, we are one down,we have lost one of our own. Nurtures, careers, listeners, feeders,parents all,we have lost a child. Let us all weep 亚伦·斯沃茨可能永远也不会像乔布斯，比尔·盖茨，扎克伯格那样吸引大众的目光，他的能力足以让他获取巨额财富，但他没有这样做，而是选择了一条少有人走的路。和蒂姆·伯纳斯·李一样，亚伦不关心赚钱，只关心如何真正地实现信息自由，赋权于民，他是一个纯粹的理想主义者。他能一眼看穿这个社会的不合理之处，然而思想太过超前，自身又太过敏感，在以一人之力对抗强大体制的战斗中，终究被这个时代所扼杀。互联网革命的时代已经过去，如今不仅是政府想对自由加以限制，许多互联网公司的封闭与垄断也砌起了一堵堵高墙。开放，自由，分享，这些曾经代表着互联网最核心价值观的理念正在被边缘化，亚伦身处其中，也必定感到过某种程度的孤独与无助吧。但这并非是没有希望的战斗。亚伦逝世后，那些陈旧的法律遭到了民间和法律界的猛烈攻击。国会也与时俱进，对其进行了修正，其中包括对1986年《计算机欺诈与滥用法案》进行修改的「亚伦法案」，以及促进学术论文免费化的《科学技术研究成果公平获取法案》（FASTR），后者被称为「另一个亚伦法案」。一些学者也开始在网上免费发布自己的论文，并附上 #pdftribute 标签，表达对亚伦的悼念。时间终将证明这一切。 亚伦·斯沃茨的一生，短暂而荣耀，他的故事应当被大家所熟知。他是推进信息开放的先驱，是我们这个时代的普罗米修斯。也许我们承受不了反叛者追寻自由的代价，但至少可以在生活中实践亚伦的理念，这大概也是对他最好的纪念吧。仅仅安生与当下这世界是不够的，那样子别人给你什么你就得接受什么。我觉得得有质疑的精神，我觉得从科学的态度看，你所学的一切都是暂时的，任何所学都有改口、驳斥、质疑的余地。对于社会也是，我能尽力去解决真正的基础性的问题时 ，我没法去回避它。 ——亚伦·斯沃茨 作者：邓宣颖链接：https://www.zhihu.com/question/24928691/answer/40318542来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 穷则独善其身．达则兼济天下，愿自己也能到兼济天下的地步吧！ 观看地址：http://www.bilibili.com/video/av1340596/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python解析json]]></title>
      <url>%2F2016%2F12%2F07%2Fpython%E8%A7%A3%E6%9E%90json%2F</url>
      <content type="text"><![CDATA[JSON函数JSON(JavaScript Object Notation, JS 对象标记) 是一种轻量级的数据交换格式。它基于 ECMAScript 规范的一个子集，采用完全独立于编程语言的文本格式来存储和表示数据。简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。 易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。 使用JSON需要导入json库：import json。函数 描述json.dumps 将 Python 对象编码成 JSON 字符串json.loads 将已编码的 JSON 字符串解码为 Python 对象 json.dumps语法： json.dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding=”utf-8”, default=None, sort_keys=False, **kw) 实例以下实例将数组编码为 JSON 格式数据： #!/usr/bin/python import json data = {'number': 6, 'name': 'Pythontab'} jsonData = json.dumps(data) print jsonData 以上代码执行结果为： {"number": 6, "name": "Pythontab"}` 注意： 大家可能发现，执行上述转换以后，数据并没有发生变化，这里要说一下： 在json中双引号才是标注的字符串分割符号，单引号不标准。 使用参数让 JSON 数据排序并格式化输出： #!/usr/bin/python import json data = {'number': 6, 'name': 'Pythontab'} jsonData = json.dumps(data, sort_keys=True, indent=4, separators=(',', ': ')) print jsonData 输出结果: { "name": "Pythontab", "number": 6 } python 原始类型向 json 类型的转化对照表： json.loadsjson.loads 用于解码 JSON 数据。该函数返回 Python 字段的数据类型。 语法: json.loads(s[, encoding[, cls[, object_hook[, parse_float[, parse_int[, parse_constant[, object_pairs_hook[, **kw]]]]]]]]) 实例以下实例展示了Python 如何解码 JSON 对象： #!/usr/bin/python import json jsonData = '{"number": 6, "name": "Pythontab"}' str = json.loads(jsonData) print str 以上代码执行结果为： {u’number’: 6, u’name’: u’Pythontab’}json 类型转换到 python 的类型对照表： 使用第三方库：DemjsonDemjson 是 python 的第三方模块库，可用于编码和解码 JSON 数据，包含了 JSONLint 的格式化及校验功能。Github 地址：https://github.com/dmeranda/demjson 环境配置在使用 Demjson 编码或解码 JSON 数据前，我们需要先安装 Demjson 模块。 方法1：源码安装$ tar -xvzf demjson-2.2.4.tar.gz$ cd demjson-2.2.4$ python setup.py install 方法2：直接使用pip安装pip install Demjson JSON 函数函数 描述encode 将 Python 对象编码成 JSON 字符串decode 可以使用 demjson.decode() 函数解码 JSON 数据。该函数返回 Python 字段的数据类型。 encode语法demjson.encode(self, obj, nest_level=0) decode语法demjson.decode(self, txt)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[the zen of python]]></title>
      <url>%2F2016%2F11%2F09%2Fthe-zen-of-python%2F</url>
      <content type="text"><![CDATA[pythonic是什么？the zen of python翻译过来就是python之禅，让我们感受一下python的禅意： &gt;&gt;&gt; import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren&apos;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you&apos;re Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it&apos;s a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let&apos;s do more of those! 简单翻译几句： 优美胜于丑陋 明了胜于晦涩 简洁胜于复杂 …… 可读性很重要 …… 从上面可知python就是要成为优美而又简洁的语言。而pythonic就是用python写出简洁而又符合规范的代码。具体的可参考：http://blog.startifact.com/posts/older/what-is-pythonic.html 怎样写出pythonic的代码？现在我也是菜鸟一个现在总结一下前辈们的经验，使自己少走一些弯路 1.严格遵照PEP 8规定的Python Coding Style来写。推荐PEP 8 — the Style Guide for Python Code看看这个也会有很多启发，不过pycharm，完美的解决了这个问题：pycharm自动遵循PEP8规范。 2.善用python标准库，这样就不会造一些重复而又无用的轮子。 3.善于利用搜索工具， 4.看requests库作者写的这份 Python Guide：The Hitchhiker’s Guide to Python!（虽说是英文但在谷歌的帮助下还是很有用的） 初学代码推荐1.大神 Armin Ronacher的博客 Blog | Armin Ronacher’s Thoughts and Writings ， 有很多代码的经验和技巧分享, 他写的一些库如 flask, werkzeug 可读性都很好 2.kennethreitz 写的一系列 python lib for human, 如 requests， tablib 等gunicorn 的作者benoitc 写的python代码基本都比较 pythonic https://github.com/benoitc , 3.不超过500 行代码的各种项目(以 Python 为主，不全是 Python) GitHub - aosabook/500lines: 500 Lines or Less 4.至于那些 web 框架如 pyramid, django 之类不是很推荐初学者去阅读，过于庞大且用了一些高级trick等让初学者难以理解 5.python_koans 阅读Python开源项目代码的原因： 在工作过程中遇到一些问题，Google和StackOverFlow等网站找不到解决办法，只能去翻源码。 对某些项目或者方向非常感兴趣，希望深入。 学习遇到瓶颈需要汲取开源项目的经验和用法来做提高。 没有目的的阅读开源项目就是耍流氓。浪费了时间，但是能学到的东西也很少。怎么样根据自身情况去阅读呢？ 和兴趣以及工作契合。举个例子，工作中没有机会用到Celery又不是想自己造个轮子，读它的源码做什么？所以要从平时能接触到的那些项目中选取。 一个方向只看一两个典型的就可以了。并不是堆的多了更好，有时候反而选择太多会懵。 不同技术阶段的选择代码量、复杂度不一样的项目，下面会具体推荐。 清楚自己看代码的目的。就是你看代码是想了解人家怎么设计、调试BUG、还是只是想学习正确的编程用法呢？其实没有必要细抠每个代码细节，有时候当黑盒看，知道输入输出就可以了。 -]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[你为什么喜欢阿森纳]]></title>
      <url>%2F2016%2F11%2F07%2F%E4%BD%A0%E4%B8%BA%E4%BB%80%E4%B9%88%E5%96%9C%E6%AC%A2%E9%98%BF%E6%A3%AE%E7%BA%B3%2F</url>
      <content type="text"><![CDATA[人生就像阿森纳， 就算你很用心经营你的俱乐部， 培养青训，花小钱买一些不知名的苗子培养起来。 但你始终拿不到冠军， 人生就是这样，在磨砺中成长，在拼搏中辉煌， 但你始终还是斗不过那些富二代。 人生就像阿森纳， 你的队长，你的核心球员总是在你争冠的路上离你而去。 人生就是这样，一路走来，你努力着试图变的更优秀， 但你的女友还是纷纷离你而去。 人生就像阿森纳 你的进攻水银泻地，你的传控在英超独树一帜， 但拿到冠军的往往并不是踢的好看的球队。 人生就是这样，有些人每天都在盯着你看，瞧着你犯错出丑， 他们并不关心你的过程，只盯着你的结果去看。 人生就像阿森纳 很少有人能在阿森纳呆上很久， 今天你来，明天他走。 人生就是这样，在人来人往中度过了自己的一生。 人生就像阿森纳 你也想拥有阿圭罗，龅牙苏这样摧城拔寨的超级射手。但无奈你没有，你只能用射术不精但身板结实的吉鲁为你的中场牵线搭桥。 人生就是这样，当你没有能力在你的领域内呼风唤雨的时候， 那就踏实的做好你能做的，不要好高骛远。 人生就像阿森纳， 本赛季你一直以微弱的优势领跑积分榜，很多人都在谈论着你， 说这个赛季花了重磅引进了厄齐尔，你最有可能夺冠了。 但温格深知，球队的伤病以及曼城切尔西的强势， 想夺冠谈何容易。 人生就是这样，别人只看到了你光鲜亮丽的一面， 内心真正的痛苦和恐惧只有你自己知道 人生就像阿森纳， 我虽然不是高富帅， 但我永远不会承认自己是个屌丝， 喜欢你，阿森纳， 期待你能继续前进，向着一项项桂冠发起冲击， 也希望我们的人生能不断克服艰难险阻， 迸发出最璀璨的光芒 链接：https://www.zhihu.com/question/19904606/answer/21317556]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python3.5编写zip破解器]]></title>
      <url>%2F2016%2F11%2F07%2Fpython3-5%E7%BC%96%E5%86%99zip%E7%A0%B4%E8%A7%A3%E5%99%A8%2F</url>
      <content type="text"><![CDATA[zipfile模块想要对zip文件进行操作就需要用到zipfile模块，用help(zipfile)来查看这个模块的作用： 其中extractall（）方法有三个参数： path指定解压后文件的存储位置 members（可选）指定要Zip文件中要解压的文件，这个文件名称必须是通过namelist()方法返回列表的子集 pwd指定Zip文件的解压密码通过这三个参数extractall()方法可以用参数来指定密码，从而来解压文件。 测试zipfile模块import zipfile zFile = zipfile.ZipFile(&apos;niu.zip&apos;) #创建ZipFile对象 zFile.extractall(path=&apos;\Desktop\demo&apos;,pwd=b&apos;1314&apos;) 这就表示用来测试桌面上demo文件夹中的niu.zip密码是否为1314，将代码保存为demo.py。进入文件夹中运行demo.py: 没有报错信息就代表密码正确。但这时候我们是知道密码来进行测试的，显然这是不够的。为了试出正确的密码我们需要建立一个字典文件，从字典文件中提取一个个的密码进行暴力破解。 提高性能argparee模块argparse是python用于解析命令行参数和选项的标准模块，用于代替已经过时的optparse模块。argparse模块的作用是用于解析命令行参数。 首先我们导入了argparse这个模块，通过argparse.ArgumentParser方法来获得解析器对象。description是在我们输出命令行参数帮助信息时起到描述的作用。add_argument方法用来添加我们需要解析的参数，可以看到我们这里添加了-n参数，dest相当于存储命令行参数值的变量，type表示我们输入的类型，这里是str。help是用来说明参数的，和description一样在我们输出命令行帮助信息时会显示出来。 分析需求我们要先写一个函数来对zip文件进行解压。在函数里设置zipFile，password，savePath三个参数。 zipFile表示一个ZipFile对象。 password表示解压ZipFile的密码 savePath表示解压后文件存储的路径。 def tryZipPwd(zipFile,password,savePath): try: zipFile.extractall(path=savePath,pwd=password.encode(&apos;utf-8&apos;)) print(&apos;[+] Zip File decompression success,password: %s&apos; % (password)) return True except: print(&apos;[-] Zip File decompression failed,password: %s&apos; % (password)) return False 我们还要新建一个ZipFile对象，来循环调用字典中的密码，在调用解压的函数还判断密码是否正确，正确的话循环停止。 with zipfile.ZipFile(zFilePath) as zFile: with open(pwdFilePath) as f: for pwd in f.readlines(): p,f = split(zFilePath) dirName = f.split(&apos;.&apos;)[0] dirPath = join(p, dirName) try: os.mkdir(dirPath) except: pass ok = tryZipPwd(zFile, pwd.strip(&apos;\n&apos;),dirPath) if ok: break 最后我们来实现参数解析功能，首先分析一下我们都需要哪些参数！ 通过解压Zip文件的函数来看我们需要知道密码和存储路径这两个参数，而密码则是从密码字典文件中读取出来的，所以我们需要在程序运行时添加密码文件路径和文件存储路径这两个参数。 # 这里用描述创建了ArgumentParser对象 parser = argparse.ArgumentParser(description=&apos;Brute Crack Zip&apos;) # 添加-H命令dest可以理解为咱们解析时获取-H参数后面值的变量名,help是这个命令的帮助信息 parser.add_argument(&apos;-f&apos;, dest=&apos;zFile&apos;, type=str, help=&apos;The zip file path.&apos;) parser.add_argument(&apos;-w&apos;, dest=&apos;pwdFile&apos;, type =str, help=&apos;Password dictionary file.&apos;) 这样主要的准备工作就完成了，开始进行整合和编写代码了。 代码实现import zipfile import argparse import os from os.path import * def tryZipPwd(zipFile,password,savePath): try: zipFile.extractall(path=savePath,pwd=password.encode(&apos;utf-8&apos;)) print(&apos;[+] Zip File decompression success,password: %s&apos; % (password)) return True except: print(&apos;[-] Zip File decompression failed,password: %s&apos; % (password)) return False def main(): # 这里用描述创建了ArgumentParser对象 parser = argparse.ArgumentParser(description=&apos;Brute Crack Zip&apos;) # 添加-H命令dest可以理解为咱们解析时获取-H参数后面值的变量名,help是这个命令的帮助信息 parser.add_argument(&apos;-f&apos;, dest=&apos;zFile&apos;, type=str, help=&apos;The zip file path.&apos;) parser.add_argument(&apos;-w&apos;, dest=&apos;pwdFile&apos;, type =str, help=&apos;Password dictionary file.&apos;) zFilePath = None pwdFilePath = None try: options = parser.parse_args() zFilePath = options.zFile pwdFilePath = options.pwdFile except: print(parser.parse_args([&apos;-h&apos;])) exit(0) if zFilePath == None or pwdFilePath == None: print(parser.parse_args([&apos;-h&apos;])) exit(0) with zipfile.ZipFile(zFilePath) as zFile: with open(pwdFilePath) as f: for pwd in f.readlines(): p,f = split(zFilePath) dirName = f.split(&apos;.&apos;)[0] dirPath = join(p, dirName) try: os.mkdir(dirPath) except: pass ok = tryZipPwd(zFile, pwd.strip(&apos;\n&apos;),dirPath) if ok: break if __name__ == &apos;__main__&apos;: main() 如果代码运行不出来请注意代码的缩进（markdown粘贴代码太麻烦了，所以代码可能会因为缩进而出问题） 运行效果 进入demo.py所在文件夹，输入：python demo.py -f niu.zip -w zidian.txt 其中： niu.zip可换成你的压缩文件 zidian.txt换成你的字典文件 总结：感觉没有什么大用，破解还是要看字典的丰富程度和运气。建议大家去其他网站搜索比较大的字典，来增加破解概率。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python列表]]></title>
      <url>%2F2016%2F11%2F06%2Fpython%E5%88%97%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[使用IDLE来学习python安装python3时，会得到一个IDLE，这是python的集成开发环境，尽管简单，但及其实用 IDLE使用区分颜色的语法来突出显示代码。默认的，内置函数都是紫色，字符串时绿色，python语言的关键字（如if）为橙色。生成的所有结果显示为蓝色。如果不喜欢这些颜色也可调整IDLE的首选项就可以改变颜色选择。 此外，IDLE也很清楚python的缩进语法（python要求代码块缩进）。他会根据需要自动缩进。 下面介绍编写Python程序时常用的IDLE选项，下面按照不同的菜单分别列出，供初学者参考。对于“Edit”菜单，除了上面介绍的几个选项之外，常用的选项及解释如下所示： Undo：撤销上一次的修改 Redo：重复上一次的修改 Cut：将所选文本剪切至剪贴板 Copy：将所选文本复制到剪贴板 Paste：将剪贴板的文本粘帖到光标所在位置 Find：在窗口中查找单词或模式 Find in files：在指定的文件中查找单词或模式 Replace：替换单词或模式 Go to line：将光标定位到指定行首。 对于“Format”菜单，常用的选项及解释如下所示 Indent region：使所选内容右移一级，即增加缩进量 Dedent region：使所选内容组左移一级，即减少缩进量 Comment out region：将所选内容变成注释 Uncomment region：去除所选内容每行前面的注释符 New indent width：重新设定制表位缩进宽度，范围2～16，宽度为2相当于1个空格 Expand word：单词自动完成 Toggle tabs：打开或关闭制表位。 IDLE提供了大量的特性###TAB完成###先键入一些代码，然后按下TAB键。IDLE会提供一些建议，帮助你完成这个语句: ###回退代码语句###按下ALT-P，可以回到IDLE中之前输入的代码语句，或者按下ALT-N可以移至下个代码语句（如果有的话）。可以利用这两个按键组合在IDLE中已输入的所有代码之间快速转换，根据需要重新执行其中的任何代码语句。 ALT-P表示“前一个”（previous） ALT-N表示“后一个”（next） ###调整IDLE的首选项句###依次选择菜单上Options – Configure IDLE 具体设置可参考linux公社的这篇文章http://www.linuxidc.com/Linux/2012-07/66129.htm。 python列表任何值得着手创建的程序都必然会处理数据。为了降低复杂性，通常可以把数据组织为列表。 使用括号中记号法访问列表数据首先定义一个名字列表，然后使用print（）在屏幕上显示这列表。。接下来，使用len（）得到列表中有多少个数据项，然后再访问并显示第二个数据项的值： &gt;&gt;&gt; cast=[&quot;a&quot;,&quot;b&quot;,&quot;c&quot;] &gt;&gt;&gt; print(cast) [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] &gt;&gt;&gt; print(len(cast)) &gt;&gt;&gt; print(cast[1]) b]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[“虚拟机安装ubuntu”]]></title>
      <url>%2F2016%2F11%2F05%2F%E2%80%9C%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85ubuntu%E2%80%9D%2F</url>
      <content type="text"><![CDATA[距离ubuntu最新版发布已经差不多半年了，博主近来对linux系统有了兴 趣，奈何资金不足无法购置一台新机来安装ubuntu。所以想到了虚拟机。 虚拟机的选择1.VMwareWorkstation，功能强大，虚拟机的显卡也不错。VMware缺点是很不绿色，会对你的系统有一些影响。而vmare workstation本身有点臃肿，占用系统资源比较多。 2. Virtualbox虚拟机相对比VMWare workstation轻量级一些，运行一般的游戏的话，性能不输于vmware。但是配置起来相对麻烦，而且最大的弱点就是虚拟机和宿主机之间文件共享比较困难，不能像vmware那样用鼠标一拖就行。 3.VMware Player精简了很多功能，但VMware Workstation提供的基本功能都被保留了下来，并且还有所增强，如对光驱、软驱、移动硬盘、闪存等设备的支持，以及对用户网络和多种虚拟机文件格式的支持。 本文选择virtualbox虚拟机。 安装ubuntu32位：http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-i386.iso 64位：http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso 安装时一步步按照默认就行。然后启动。 找到ubuntu的下载目录就行，虚拟机会自动安装系统，安装过程中会出现一幅世界地图让你选地区（默认的是上海）直接点默认就行。 解决全屏问题安装好后你会发现ubuntu并不是全屏的，而是在屏幕中央的一小块。这时候就需要我们自己动手解决了。解决方法：在VirtualBox菜单栏中选择【设备】-&gt;【安装增强功能】 点击安装增强功能成功后ubuntu即可全屏。]]></content>
    </entry>

    
  
  
</search>
